{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1efb8fc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### First Unet Tests\n",
    "\n",
    "all code modified from https://github.com/milesial/Pytorch-UNet/tree/e36c782fbfc976b7326182a47dd7213bd3360a7e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98956842",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from segmentation.unet_utils.data_loading import BasicDataset, CarvanaDataset\n",
    "from segmentation.unet_utils.dice_score import dice_loss, multiclass_dice_coeff, dice_coeff\n",
    "from segmentation.unet import UNet\n",
    "\n",
    "import torchshow as ts\n",
    "import copy\n",
    "\n",
    "# dir_img = Path('./data/imgs/')\n",
    "dir_img = Path('C:/2022_Summer_Intern/UNet_Training_With_Images/Carvana/Input')\n",
    "# dir_mask = Path('./data/masks/')\n",
    "dir_mask = Path('C:/2022_Summer_Intern/UNet_Training_With_Images/Carvana/Target')\n",
    "# dir_checkpoint = Path('./checkpoints/')\n",
    "dir_checkpoint = Path('C:/2022_Summer_Intern/UNet_Training_With_Images/checkpoints')\n",
    "\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353acb5a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Your Tasks\n",
    "Below I have pasted in two (untested) functions for 1) evaluating a unet on a set of images and 2) training a unet on a set of image and segmentation mask pairs.\n",
    "You should:\n",
    "- First, familiarize yourself with the unet structure (backend/segmentation/unet/unet_model.py)\n",
    "- Then, download this small training dataset I've prepared here: https://we.tl/t-5bzkQhZdsZ and familiarize yourself with this (it consists of a folder of images of cars and another folder with a segmentation map)\n",
    "- Scroll down to the scripting area in this notebook, and attempt to read in the data using the dataloaders prepared.\n",
    "- Consult with me at this point so we can eval what's going on.\n",
    "- After this, we'll start training the model and looking at the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540eb95d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "408d8339",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(net, dataloader, device):\n",
    "    net.eval()\n",
    "    num_val_batches = len(dataloader)\n",
    "    dice_score = 0\n",
    "\n",
    "    # iterate over the validation set\n",
    "    for batch in tqdm(dataloader, total=num_val_batches, desc='Validation round', unit='batch', leave=False):\n",
    "        image, mask_true = batch['image'], batch['mask']\n",
    "        # move images and labels to correct device and type\n",
    "        image = image.to(device=device, dtype=torch.float32)\n",
    "        mask_true = mask_true.to(device=device, dtype=torch.long)\n",
    "        mask_true = F.one_hot(mask_true, net.n_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # predict the mask\n",
    "            mask_pred = net(image)\n",
    "            \n",
    "            combi_mask = torch.empty(1, 3, 640, 959)\n",
    "            for i in range(640):\n",
    "                for j in range(959):\n",
    "                    if (mask_pred[0][0][i][j] < 0.5 and mask_pred[0][1][i][j] > 0.5):\n",
    "                        combi_mask[0][0][i][j] = 1\n",
    "                        combi_mask[0][1][i][j] = 0\n",
    "                        combi_mask[0][2][i][j] = 0\n",
    "                    else:\n",
    "                        combi_mask[0][0][i][j] = image[0][0][i][j]\n",
    "                        combi_mask[0][1][i][j] = image[0][1][i][j]\n",
    "                        combi_mask[0][2][i][j] = image[0][2][i][j]\n",
    "            \n",
    "            \n",
    "            # This prints the image, segmentation prediction, true segmentation with torchshow\n",
    "            ts.show([torch.squeeze(image), torch.squeeze(mask_pred), torch.squeeze(combi_mask), torch.squeeze(mask_true)])\n",
    "            # ts.show(mask_pred)\n",
    "            \n",
    "            # print(f\"image: {image}\")\n",
    "            # print(f\"mask_pred: {mask_pred}\")\n",
    "            # print(f\"mask_true: {mask_true}\")\n",
    "            # print(f\"mask_true.unique: {mask_true.unique()}\")\n",
    "\n",
    "            # convert to one-hot format\n",
    "            if net.n_classes == 1:\n",
    "                mask_pred = (F.sigmoid(mask_pred) > 0.5).float()\n",
    "                # compute the Dice score\n",
    "                dice_score += dice_coeff(mask_pred, mask_true, reduce_batch_first=False)\n",
    "            else:\n",
    "                mask_pred = F.one_hot(mask_pred.argmax(dim=1), net.n_classes).permute(0, 3, 1, 2).float()\n",
    "                # compute the Dice score, ignoring background\n",
    "                dice_score += multiclass_dice_coeff(mask_pred[:, 1:, ...], mask_true[:, 1:, ...],\n",
    "                                                    reduce_batch_first=False)\n",
    "\n",
    "\n",
    "        # For checking if the middle parts are empty or just the image quality being bad\n",
    "        \"\"\"\n",
    "        # size = [1,2,640,959]\n",
    "        # roi: 450,640 -> 650,800\n",
    "        \n",
    "        new_tensor = torch.empty(4, 640, 959)\n",
    "        for i in range(640):\n",
    "            for j in range(959):\n",
    "                if (mask_pred[0][0][i][j] == 1 and mask_pred[0][1][i][j] == 1):\n",
    "                    new_tensor[0][i][j] = 0\n",
    "                    new_tensor[1][i][j] = 0\n",
    "                    new_tensor[2][i][j] = 1\n",
    "                    new_tensor[3][i][j] = 0\n",
    "                elif (mask_pred[0][0][i][j] == 1 and mask_pred[0][1][i][j] == 0):\n",
    "                    new_tensor[0][i][j] = 1\n",
    "                    new_tensor[1][i][j] = 0\n",
    "                    new_tensor[2][i][j] = 0\n",
    "                    new_tensor[3][i][j] = 0\n",
    "                elif (mask_pred[0][0][i][j] == 0 and mask_pred[0][1][i][j] == 1):\n",
    "                    new_tensor[0][i][j] = 0\n",
    "                    new_tensor[1][i][j] = 1\n",
    "                    new_tensor[2][i][j] = 0\n",
    "                    new_tensor[3][i][j] = 0\n",
    "                else:\n",
    "                    new_tensor[0][i][j] = 0\n",
    "                    new_tensor[1][i][j] = 0\n",
    "                    new_tensor[2][i][j] = 0\n",
    "                    new_tensor[3][i][j] = 1\n",
    "\n",
    "        print(new_tensor)\n",
    "\n",
    "        print(\"Unique: \")\n",
    "        print(new_tensor.unique())\n",
    "        ts.show(new_tensor)\"\"\"\n",
    "\n",
    "        # break\n",
    "\n",
    "        \n",
    "        \n",
    "        # size = [1,2,640,959]\n",
    "        # roi: 450,640 -> 650,800\n",
    "        \n",
    "\n",
    "    net.train()\n",
    "\n",
    "    # Fixes a potential division by zero error\n",
    "    if num_val_batches == 0:\n",
    "        return dice_score\n",
    "    return dice_score / num_val_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35aa33f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = UNet(n_channels=3, n_classes=2, bilinear=False)\n",
    "net.train()\n",
    "modelweights = torch.load(f=\"C:\\\\Users\\\\s2137314\\\\Downloads\\\\checkpoint_epoch100.pth\", map_location=torch.device(\"cpu\"))\n",
    "net.load_state_dict(state_dict = modelweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c4ed3c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                          \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(net, val_loader, device = torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b93b9e93",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_net(net,\n",
    "              device,\n",
    "              epochs: int = 5,\n",
    "              batch_size: int = 1,\n",
    "              learning_rate: float = 1e-5,\n",
    "              val_percent: float = 0.1,\n",
    "              save_checkpoint: bool = True,\n",
    "              img_scale: float = 0.5,\n",
    "              amp: bool = False):\n",
    "    # 1. Create dataset\n",
    "    dataset = BasicDataset(dir_img, dir_mask, img_scale)\n",
    "\n",
    "    # 2. Split into train / validation partitions\n",
    "    n_val = int(len(dataset) * val_percent)\n",
    "    n_train = len(dataset) - n_val\n",
    "    train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "    # 3. Create data loaders\n",
    "    loader_args = dict(batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "    # (Initialize logging)\n",
    "    experiment = wandb.init(project='U-Net', resume='allow', anonymous='must')\n",
    "    experiment.config.update(dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n",
    "                                  val_percent=val_percent, save_checkpoint=save_checkpoint, img_scale=img_scale,\n",
    "                                  amp=amp))\n",
    "\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {learning_rate}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_checkpoint}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {img_scale}\n",
    "        Mixed Precision: {amp}\n",
    "    ''')\n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    global_step = 0\n",
    "\n",
    "    # 5. Begin training\n",
    "    for epoch in range(1, epochs+1):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                images = batch['image']\n",
    "                true_masks = batch['mask']\n",
    "\n",
    "                assert images.shape[1] == net.n_channels, \\\n",
    "                    f'Network has been defined with {net.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32)\n",
    "                true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=amp):\n",
    "                    masks_pred = net(images)\n",
    "                    loss = criterion(masks_pred, true_masks) \\\n",
    "                           + dice_loss(F.softmax(masks_pred, dim=1).float(),\n",
    "                                       F.one_hot(true_masks, net.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                                       multiclass=True)\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "                global_step += 1\n",
    "                epoch_loss += loss.item()\n",
    "                experiment.log({\n",
    "                    'train loss': loss.item(),\n",
    "                    'step': global_step,\n",
    "                    'epoch': epoch\n",
    "                })\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                # Evaluation round\n",
    "                division_step = (n_train // (10 * batch_size))\n",
    "                if division_step > 0:\n",
    "                    if global_step % division_step == 0:\n",
    "                        histograms = {}\n",
    "                        for tag, value in net.named_parameters():\n",
    "                            tag = tag.replace('/', '.')\n",
    "                            histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n",
    "                            histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n",
    "\n",
    "                        val_score = evaluate(net, val_loader, device)\n",
    "                        scheduler.step(val_score)\n",
    "\n",
    "                        logging.info('Validation Dice score: {}'.format(val_score))\n",
    "                        experiment.log({\n",
    "                            'learning rate': optimizer.param_groups[0]['lr'],\n",
    "                            'validation Dice': val_score,\n",
    "                            'images': wandb.Image(images[0].cpu()),\n",
    "                            'masks': {\n",
    "                                'true': wandb.Image(true_masks[0].float().cpu()),\n",
    "                                'pred': wandb.Image(torch.softmax(masks_pred, dim=1).argmax(dim=1)[0].float().cpu()),\n",
    "                            },\n",
    "                            'step': global_step,\n",
    "                            'epoch': epoch,\n",
    "                            **histograms\n",
    "                        })\n",
    "\n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(net.state_dict(), str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch)))\n",
    "            logging.info(f'Checkpoint {epoch} saved!')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef227b40",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Scripting Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b6d4fbf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creating dataset with 27 examples\n"
     ]
    }
   ],
   "source": [
    "# Can you get this to work?\n",
    "# I only changed section 1 and the other seemed to work\n",
    "\n",
    "# I just randomly assigned values to the variables below\n",
    "img_scale = 0.5\n",
    "val_percent: float = 0.1\n",
    "\n",
    "# 1. Create dataset\n",
    "try:\n",
    "    \"\"\"\n",
    "    Original code: dataset = CarvanaDataset(dir_img, dir_mask, img_scale)\n",
    "    However, it is not loading the segmentation images (mask)\n",
    "    as the mask_suffix is set to '_mask' in CarvanaDataset\n",
    "    Instead. the mask_suffix should be simply '' so BasicDataset is used instead\n",
    "    \"\"\"\n",
    "    dataset = BasicDataset(dir_img, dir_mask, img_scale)\n",
    "except (AssertionError, RuntimeError):\n",
    "    dataset = BasicDataset(dir_img, dir_mask, img_scale)\n",
    "\n",
    "# 2. Split into train / validation partitions\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "# 3. Create data loaders\n",
    "loader_args = dict(batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d287151",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000001B24275ED48>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25616\\3639806349.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "print(train_loader)\n",
    "for batch in train_loader:\n",
    "    print(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b51df42d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25616\\1430953583.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchshow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "import torchshow as ts\n",
    "ts.show(image[0])\n",
    "ts.show(mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8338075a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25616\\187118837.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;31m# N(batch number), C(Channels), H(Height of Image), W(Width of image)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "image.shape # N(batch number), C(Channels), H(Height of Image), W(Width of image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "504e9103",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Can you start training the model on the cars dataset (starter code below)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a5b50fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n",
      "Network:\n",
      "\t3 input channels\n",
      "\t2 output channels (classes)\n",
      "\tTransposed conv upscaling\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1qwozpi0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.122 MB of 1.122 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning rate</td><td>███▁</td></tr><tr><td>step</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇█</td></tr><tr><td>train loss</td><td>█▇▅▅▄▃▂▁▇▆</td></tr><tr><td>validation Dice</td><td>▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>learning rate</td><td>0.0</td></tr><tr><td>step</td><td>10</td></tr><tr><td>train loss</td><td>1.03598</td></tr><tr><td>validation Dice</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fearless-valley-15</strong>: <a href=\"https://wandb.ai/anony-mouse-348608/U-Net/runs/1qwozpi0?apiKey=5eb9cf60634f845069ff31841eb4d286e956cfa1\" target=\"_blank\">https://wandb.ai/anony-mouse-348608/U-Net/runs/1qwozpi0?apiKey=5eb9cf60634f845069ff31841eb4d286e956cfa1</a><br/>Synced 5 W&B file(s), 12 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220712_132850-1qwozpi0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1qwozpi0). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\2022_Summer_Intern\\Automatic-Gel-Analysis\\backend\\segmentation\\wandb\\run-20220712_133159-1w5ywkvl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/anony-mouse-348608/U-Net/runs/1w5ywkvl?apiKey=5eb9cf60634f845069ff31841eb4d286e956cfa1\" target=\"_blank\">breezy-cloud-16</a></strong> to <a href=\"https://wandb.ai/anony-mouse-348608/U-Net?apiKey=5eb9cf60634f845069ff31841eb4d286e956cfa1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   8%|████▏                                               | 2/25 [00:24<04:47, 12.52s/img, loss (batch)=1.16]\n",
      "Validation round:   0%|                                                                       | 0/2 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  50%|███████████████████████████████▌                               | 1/2 [00:05<00:05,  5.11s/batch]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.52s/batch]\u001b[A\n",
      "Epoch 1/1:  16%|████████▎                                           | 4/25 [01:01<05:33, 15.87s/img, loss (batch)=1.08]\u001b[A\n",
      "Validation round:   0%|                                                                       | 0/2 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  50%|███████████████████████████████▌                               | 1/2 [00:05<00:05,  5.10s/batch]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.58s/batch]\u001b[A\n",
      "Epoch 1/1:  24%|████████████▏                                      | 6/25 [01:37<05:13, 16.52s/img, loss (batch)=0.717]\u001b[A\n",
      "Validation round:   0%|                                                                       | 0/2 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  50%|███████████████████████████████▌                               | 1/2 [00:04<00:04,  4.96s/batch]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.50s/batch]\u001b[A\n",
      "Epoch 1/1:  32%|████████████████▎                                  | 8/25 [02:13<04:43, 16.68s/img, loss (batch)=0.872]\u001b[A\n",
      "Validation round:   0%|                                                                       | 0/2 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  50%|███████████████████████████████▌                               | 1/2 [00:05<00:05,  5.15s/batch]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.63s/batch]\u001b[A\n",
      "Epoch 1/1:  40%|████████████████████                              | 10/25 [02:48<04:11, 16.78s/img, loss (batch)=0.761]\u001b[A\n",
      "Validation round:   0%|                                                                       | 0/2 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  50%|███████████████████████████████▌                               | 1/2 [00:05<00:05,  5.06s/batch]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.48s/batch]\u001b[A\n",
      "Epoch 1/1:  48%|████████████████████████                          | 12/25 [03:24<03:40, 16.94s/img, loss (batch)=0.792]\u001b[A\n",
      "Validation round:   0%|                                                                       | 0/2 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  50%|███████████████████████████████▌                               | 1/2 [00:04<00:04,  4.98s/batch]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.54s/batch]\u001b[A\n",
      "Epoch 1/1:  56%|████████████████████████████                      | 14/25 [03:59<03:05, 16.85s/img, loss (batch)=0.707]\u001b[A\n",
      "Validation round:   0%|                                                                       | 0/2 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  50%|███████████████████████████████▌                               | 1/2 [00:05<00:05,  5.07s/batch]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.56s/batch]\u001b[A\n",
      "Epoch 1/1:  64%|████████████████████████████████                  | 16/25 [04:35<02:31, 16.79s/img, loss (batch)=0.733]\u001b[A\n",
      "Validation round:   0%|                                                                       | 0/2 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  50%|███████████████████████████████▌                               | 1/2 [00:05<00:05,  5.03s/batch]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.54s/batch]\u001b[A\n",
      "Epoch 1/1:  72%|████████████████████████████████████              | 18/25 [05:10<01:57, 16.82s/img, loss (batch)=0.693]\u001b[A\n",
      "Validation round:   0%|                                                                       | 0/2 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  50%|███████████████████████████████▌                               | 1/2 [00:05<00:05,  5.19s/batch]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.58s/batch]\u001b[A\n",
      "Epoch 1/1:  80%|████████████████████████████████████████          | 20/25 [05:45<01:24, 16.81s/img, loss (batch)=0.571]\u001b[A\n",
      "Validation round:   0%|                                                                       | 0/2 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  50%|███████████████████████████████▌                               | 1/2 [00:05<00:05,  5.13s/batch]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.48s/batch]\u001b[A\n",
      "Epoch 1/1:  88%|████████████████████████████████████████████▉      | 22/25 [06:21<00:50, 16.82s/img, loss (batch)=0.58]\u001b[A\n",
      "Validation round:   0%|                                                                       | 0/2 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  50%|███████████████████████████████▌                               | 1/2 [00:05<00:05,  5.10s/batch]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.63s/batch]\u001b[A\n",
      "Epoch 1/1:  96%|████████████████████████████████████████████████  | 24/25 [06:57<00:16, 16.92s/img, loss (batch)=0.713]\u001b[A\n",
      "Validation round:   0%|                                                                       | 0/2 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  50%|███████████████████████████████▌                               | 1/2 [00:05<00:05,  5.13s/batch]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.54s/batch]\u001b[A\n",
      "Epoch 1/1: 100%|██████████████████████████████████████████████████| 25/25 [07:20<00:00, 17.61s/img, loss (batch)=0.739]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "batch_size = 1\n",
    "learning_rate = 1e-5\n",
    "load = False # initializes the weights randomly\n",
    "# To initialize the pre-trainined weights:\n",
    "# load = \"C:\\\\2022_Summer_Intern\\\\UNet Training With Images\\\\Pre-trained\\\\unet_carvana_scale0.5_epoch2.pth\"\n",
    "scale = 0.5\n",
    "amp = True\n",
    "bilinear = False\n",
    "classes = 2\n",
    "val = 10\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device {device}')\n",
    "\n",
    "# Change here to adapt to your data\n",
    "# n_channels=3 for RGB images\n",
    "# n_classes is the number of probabilities you want to get per pixel\n",
    "net = UNet(n_channels=3, n_classes=classes, bilinear=bilinear) # initializing random weights\n",
    "\n",
    "print(f'Network:\\n'\n",
    "             f'\\t{net.n_channels} input channels\\n'\n",
    "             f'\\t{net.n_classes} output channels (classes)\\n'\n",
    "             f'\\t{\"Bilinear\" if net.bilinear else \"Transposed conv\"} upscaling')\n",
    "\n",
    "if load:\n",
    "    net.load_state_dict(torch.load(load, map_location=device))\n",
    "    logging.info(f'Model loaded from {load}')\n",
    "\n",
    "net.to(device=device)\n",
    "\n",
    "# Modify the number of workers in dataloader to 0 if not working (due to memory issues)\n",
    "# Expected error: DataLoader worker (pid(s) 25424, 23564, 24580, 18048) exited unexpectedly\n",
    "\n",
    "train_net(net=net,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          learning_rate=learning_rate,\n",
    "          device=device,\n",
    "          img_scale=scale,\n",
    "          val_percent=val / 100,\n",
    "          amp=amp)\n",
    "\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5cff3b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "test=None\n",
    "print(not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c32ec95",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25616\\753128632.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtensorfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "tensorfloat = evaluate(net, val_loader, device = torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6a31c157",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022_07_14_16;17;29\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import strftime\n",
    "\n",
    "base_dir = strftime(\n",
    "            \"C:/2022_Summer_Intern/UNet_Training_With_Images\"\n",
    "            \"/Model/%Y_%m_%d_%H;%M;%S.toml\")\n",
    "print(base_dir.split('.')[-2].split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a52ecbee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9970531463623047"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorfloat.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fdadb745",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tensorfloat.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b26548e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\2022_Summer_Intern\\UNet_Training_With_Images\\Model\\%Y_%m_%d_%H;%M;%S\\checkpoints\\checkpoint_epoch1.pth\n"
     ]
    }
   ],
   "source": [
    "dir_checkpoint = Path(\"C:/2022_Summer_Intern/UNet_Training_With_Images/Model/%Y_%m_%d_%H;%M;%S/checkpoints\")\n",
    "epoch = 1\n",
    "print(str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8097c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
