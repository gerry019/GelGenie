experiment_name = "MA_unet_internal_testing"  # configuration name
base_dir = '/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/segmentation_models'

[processing]
base_hardware = "MA_mac"   # Where the program is run [EDDIE/PC]
device = "GPU"    # Which processor is used [GPU/CPU]
pe = 1          # How many parallel environments (cores) needed

[data]
n_channels = 1 # channels to output to model
batch_size = 1  # Batch size for dataloader
num_workers = 1 # parallel threads to use to speed up data processing
dir_train_mask = '/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/data/processed_gels/dummy_set/masks_train'
dir_train_img = '/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/data/processed_gels/dummy_set/images_train'

#dir_train_mask = ['/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/data/processed_gels/dummy_set/masks_train',
#    '/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/data/processed_gels/maximal_set/lsdb_gels/masks',
#    '/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/data/processed_gels/maximal_set/matthew_gels/masks',
#    '/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/data/processed_gels/maximal_set/matthew_gels_2/masks']

#dir_train_img = ['/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/data/processed_gels/dummy_set/images_train',
#    '/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/data/processed_gels/maximal_set/lsdb_gels/images',
#    '/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/data/processed_gels/maximal_set/matthew_gels/images',
#    '/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/data/processed_gels/maximal_set/matthew_gels_2/images']

dir_val_img = '/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/data/processed_gels/dummy_set/images_val'
dir_val_mask = '/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/data/processed_gels/dummy_set/masks_val'
split_training_dataset = false
apply_augmentations = true
padding = false # pads all image with zeros to same size to allow for a batch size higher than 1
individual_padding = true

[model]
model_name = 'smp_unet'   # model architecture name
classes = 2     # Number of possible segmentation classes
encoder_name = 'resnet18'
[training]
loss = ['dice', 'unet_weighted_crossentropy']
loss_component_weighting = [0.5, 1.0]
class_loss_weighting = true
class_loss_weight_damper = [1.0, 0.5]
lr = 1e-5       # learning rate
epochs = 2     # Number of epochs to run
grad_scaler = false     # Use mixed precision for faster training
load_checkpoint = false    # Load model from a .pth file (Bool/epoch ID)
optimizer_type = 'adam' # Use adam optimizer
scheduler_type = 'CosineAnnealingWarmRestarts'  # No scheduler is used
save_checkpoint = true # Whether model checkpoints are saved
checkpoint_frequency = 1 # How often checkpoints are saved (per epoch)
model_cleanup_frequency = 20 # How often old checkpoints are deleted (in epochs)
wandb_track = false # Whether to track training with wandb
[training.scheduler_specs]
restart_period = 100
