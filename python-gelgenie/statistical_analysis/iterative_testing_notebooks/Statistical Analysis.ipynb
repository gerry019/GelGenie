{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3af4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d4157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_keys_and_add_prefix(data_dict, prefix):\n",
    "    \"\"\"\n",
    "    Modify keys in a dictionary by removing a prefix and adding a new prefix.\n",
    "\n",
    "    Parameters:\n",
    "    - data_dict (dict): The input dictionary to be modified.\n",
    "    - prefix (str): The prefix to be added to the modified keys.\n",
    "\n",
    "    Modifies the keys in the input dictionary by removing a prefix (if present) and adding a new prefix.\n",
    "    The modified dictionary is updated in-place.\n",
    "\n",
    "    Example:\n",
    "    >>> data_dict = {'old\\\\key_1': 10, 'old\\\\key_2': 20}\n",
    "    >>> modify_keys_and_add_prefix(data_dict, 'new_')\n",
    "    >>> print(data_dict)\n",
    "    {'new_key1': 10, 'new_key2': 20}\n",
    "    \"\"\"\n",
    "    # Iterate over a copy of keys to avoid changing the dictionary size during iteration\n",
    "    for old_key in list(data_dict.keys()):\n",
    "        # Find the index of the backslash character\n",
    "        index = old_key.find(\"\\\\\")\n",
    "        \n",
    "        # If the backslash is present, create a new key starting from the character after the backslash\n",
    "        if index != -1:\n",
    "            new_key = old_key[index + 1:]\n",
    "        else:\n",
    "            # If no backslash is found, use the original key\n",
    "            new_key = old_key\n",
    "        \n",
    "        # Remove any underscores after the backslash (if present)\n",
    "        new_key = new_key.split('_')[0] if '_' in new_key else new_key\n",
    "        \n",
    "        # Add the new prefix to the modified key\n",
    "        new_key = f\"{prefix}{new_key}\"\n",
    "        \n",
    "        # Update the dictionary with the modified key\n",
    "        data_dict[new_key] = data_dict.pop(old_key)\n",
    "\n",
    "\n",
    "def min_max_normalize(df, group_column, target_column, new_column_name=None):\n",
    "    \"\"\"\n",
    "    Min-Max normalize the values of a column in a Pandas DataFrame grouped by another column.\n",
    "\n",
    "    Parameters:\n",
    "    - df: Pandas DataFrame\n",
    "    - group_column: Column used for grouping\n",
    "    - target_column: Column to be min-max normalized\n",
    "    - new_column_name: Name for the new column with normalized values (default is 'Normalized_<target_column>')\n",
    "\n",
    "    Returns:\n",
    "    - df_normalized: DataFrame with the new column containing min-max normalized values within each group\n",
    "    \"\"\"\n",
    "    # If new_column_name is not provided, create a default name\n",
    "    if new_column_name is None:\n",
    "        new_column_name = f'Normalized_{target_column}'\n",
    "\n",
    "    # Calculate the min and max values for each group\n",
    "    min_values = df.groupby(group_column)[target_column].transform('min')\n",
    "    max_values = df.groupby(group_column)[target_column].transform('max')\n",
    "\n",
    "    # Apply the min-max normalization formula and add a new column\n",
    "    df[new_column_name] = (df[target_column] - min_values) / (max_values - min_values)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_csv_files_from_folders(parent_folder, prefix=\"ga_\"):\n",
    "    \"\"\"\n",
    "    Load CSV files from folders and create a dictionary of DataFrames with prefixed names.\n",
    "\n",
    "    Parameters:\n",
    "    - parent_folder (str): The path to the parent folder containing numbered subfolders.\n",
    "    - prefix (str): The prefix to be added to the names of the DataFrames (default is \"ga_\").\n",
    "\n",
    "    Returns:\n",
    "    - dataframes (dict): A dictionary where keys are prefixed folder names, and values are corresponding DataFrames.\n",
    "    \"\"\"\n",
    "    dataframes = {}  # Dictionary to store DataFrames\n",
    "\n",
    "    # Iterate through folders in the parent folder\n",
    "    for folder_name in os.listdir(parent_folder):\n",
    "        folder_path = os.path.join(parent_folder, folder_name)\n",
    "\n",
    "        # Check if the item in the parent folder is a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            csv_file_path = os.path.join(folder_path, \"collated_data_with_band_quality.csv\")\n",
    "\n",
    "            # Check if \"colated_data.csv\" exists in the folder\n",
    "            if os.path.isfile(csv_file_path):\n",
    "                # Read the CSV file into a DataFrame\n",
    "                dataframe = pd.read_csv(csv_file_path)\n",
    "\n",
    "                # Add the prefix to the folder name and use it as the key in the dictionary\n",
    "                prefixed_folder_name = f\"{prefix}{folder_name}\"\n",
    "                dataframes[prefixed_folder_name] = dataframe\n",
    "\n",
    "    return dataframes\n",
    "\n",
    "def min_max_normalize_multiple_inplace(dataframes_dict, group_column, target_columns, new_column_prefix=None):\n",
    "    \"\"\"\n",
    "    Min-Max normalize the values of specified columns in multiple DataFrames stored in a dictionary.\n",
    "    Add normalized columns to the existing DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframes_dict (dict): A dictionary where keys are DataFrame names and values are DataFrames.\n",
    "    - group_column (str): Column used for grouping in each DataFrame.\n",
    "    - target_columns (list): List of columns to be min-max normalized in each DataFrame.\n",
    "    - new_column_prefix (str): Prefix for the new columns with normalized values (default is 'Normalized_').\n",
    "\n",
    "    Modifies the input DataFrames in-place by adding normalized columns.\n",
    "\n",
    "    Example:\n",
    "    >>> dataframes_dict = {'df1': pd.DataFrame({'Group': ['A', 'A', 'B', 'B'], 'Values1': [10, 15, 5, 8]}),\n",
    "                           'df2': pd.DataFrame({'Group': ['C', 'C', 'D', 'D'], 'Values1': [50, 55, 45, 60]})}\n",
    "    >>> min_max_normalize_multiple_inplace(dataframes_dict, group_column='Group', target_columns=['Values1'])\n",
    "    >>> print(dataframes_dict['df1'])\n",
    "       Group  Values1  Normalized_Values1\n",
    "    0     A       10                0.00\n",
    "    1     A       15                1.00\n",
    "    2     B        5                0.00\n",
    "    3     B        8                1.00\n",
    "    \"\"\"\n",
    "    # If new_column_prefix is not provided, create a default name\n",
    "    if new_column_prefix is None:\n",
    "        new_column_prefix = 'Normalized_'\n",
    "\n",
    "    # Iterate through DataFrames in the dictionary\n",
    "    for df_name, df in dataframes_dict.items():\n",
    "        # Iterate through target columns in each DataFrame\n",
    "        for target_column in target_columns:\n",
    "            # Calculate the min and max values for each group in the current DataFrame\n",
    "            min_values = df.groupby(group_column)[target_column].transform('min')\n",
    "            max_values = df.groupby(group_column)[target_column].transform('max')\n",
    "\n",
    "            # Add a new column with the normalized values to the existing DataFrame\n",
    "            new_column_name = f\"{new_column_prefix}{target_column}\"\n",
    "            df[new_column_name] = (df[target_column] - min_values) / (max_values - min_values)\n",
    "\n",
    "        # Update the dictionary with the modified DataFrame\n",
    "        dataframes_dict[df_name] = df\n",
    "\n",
    "        \n",
    "def load_csv_files_to_dict(folder_path, prefix=\"prefix_\"):\n",
    "    \"\"\"\n",
    "    Load CSV files from a folder and create a dictionary of DataFrames with prefixed keys.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): The path to the folder containing CSV files.\n",
    "    - prefix (str): The prefix to be added to the keys of the dictionary (default is \"prefix_\").\n",
    "\n",
    "    Returns:\n",
    "    - dataframes_dict (dict): A dictionary where keys are prefixed numbers, and values are corresponding DataFrames.\n",
    "    \"\"\"\n",
    "    dataframes_dict = {}  # Dictionary to store DataFrames\n",
    "\n",
    "    # Iterate through files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file is a CSV file\n",
    "        if filename.endswith(\".csv\"):\n",
    "            # Extract the number from the filename\n",
    "            file_number = filename.split(\"_\")[0]\n",
    "\n",
    "            # Read the CSV file into a DataFrame\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            dataframe = pd.read_csv(file_path)\n",
    "\n",
    "            # Add the prefix to the number and use it as the key in the dictionary\n",
    "            key = f\"{prefix}{file_number}\"\n",
    "            dataframes_dict[key] = dataframe\n",
    "\n",
    "    return dataframes_dict\n",
    "\n",
    "\n",
    "def remove_spaces_from_column_headings_inplace(dataframes_dict):\n",
    "    \"\"\"\n",
    "    Remove spaces at the start and end of column headings in pandas DataFrames stored in a dictionary.\n",
    "    Replace the old columns with the modified column headings in-place.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframes_dict (dict): A dictionary where keys are DataFrame names and values are DataFrames.\n",
    "\n",
    "    Modifies the input DataFrames in-place by replacing old columns with modified column headings.\n",
    "    \"\"\"\n",
    "    # Iterate through DataFrames in the dictionary\n",
    "    for df_name, df in dataframes_dict.items():\n",
    "        # Remove spaces at the start and end of column headings and replace the old columns\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        # Update the dictionary with the modified DataFrame\n",
    "        dataframes_dict[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ec275",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg_path = Path(\"Data For Nathan/Data/\")\n",
    "gg_dfs = load_csv_files_to_dict(gg_path, \"gg_\")\n",
    "remove_spaces_from_column_headings_inplace(gg_dfs)\n",
    "gg_dfs = {key: gg_dfs[key] for key in sorted(gg_dfs.keys())}\n",
    "\n",
    "ga_path = Path(\"Data For Nathan/Gelanalyzer Data\")\n",
    "ga_dfs = load_csv_files_from_folders(ga_path)\n",
    "ga_dfs = {key: ga_dfs[key] for key in sorted(ga_dfs.keys())}\n",
    "\n",
    "for key, df in ga_dfs.items():\n",
    "    ga_dfs[key] = df[df['Reliable Band'] != 0].copy()\n",
    "\n",
    "reference_path = Path(\"reference_ladder_masses.csv\")\n",
    "reference_df = pd.read_csv(reference_path)\n",
    "reference_df.rename(columns={\"NEB ladder\": \"NEB\", \" ThermoFisher ladder\": \"Thermo\"}, inplace=True)\n",
    "reference_df[\"Band ID\"] = range(1, len(reference_df) + 1)\n",
    "reference_df = pd.melt(reference_df, id_vars=[\"Band ID\"], value_vars=[\"NEB\", \"Thermo\"], var_name=\"Ladder\", value_name=\"Intensity\")\n",
    "reference_df['Normalized_Intensity'] = reference_df.groupby(\"Ladder\")[\"Intensity\"].transform(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "reference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8035e45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ga_columns = ['Raw Volume', 'Background Corrected Volume']\n",
    "gg_columns = ['Raw Volume','Local Corrected Volume', 'Global Corrected Volume']\n",
    "\n",
    "min_max_normalize_multiple_inplace(ga_dfs, 'Lane ID', ga_columns)\n",
    "min_max_normalize_multiple_inplace(gg_dfs, 'Lane ID', gg_columns)\n",
    "\n",
    "normalized_gg_columns = ['Normalized_Raw Volume', 'Normalized_Local Corrected Volume', 'Normalized_Global Corrected Volume']\n",
    "normalized_ga_columns = ['Normalized_Raw Volume', 'Normalized_Background Corrected Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac9d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in gg_dfs.items():\n",
    "    df['App'] = \"GG\"\n",
    "    df['Gel ID'] = key\n",
    "    \n",
    "for key, df in ga_dfs.items():\n",
    "    df['App'] = \"GA\"\n",
    "    df['Gel ID'] = key\n",
    "    \n",
    "concatenated_df = pd.concat([df for df in gg_dfs.values()] + [df for df in ga_dfs.values()], ignore_index=True)\n",
    "concatenated_df['Gel ID'] = concatenated_df['Gel ID'].str.extract(r'_(\\d+)')\n",
    "concatenated_df['Gel ID'] = concatenated_df['Gel ID'].astype(int)\n",
    "concatenated_df['Ladder'] = \"Temp\"\n",
    "concatenated_df.loc[concatenated_df[\"Gel ID\"].isin([0,1,2,3,4,5,6,7,8,9,10,11,12]), \"Ladder\"] = \"Thermo\"\n",
    "concatenated_df.loc[concatenated_df[\"Gel ID\"].isin([13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,29]), \"Ladder\"] = \"NEB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f8ef29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.violinplot(data=concatenated_df, x='Lane ID', y='Normalized_Raw Volume', hue='App', split=True, inner='quart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a8b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df = pd.melt(concatenated_df, id_vars=['Lane ID', 'Band ID', 'Gel ID', 'App'],\n",
    "                    value_vars=['Pixel Count', 'Average Intensity', 'Raw Volume', 'Local Corrected Volume',\n",
    "                                'Global Corrected Volume', 'Normalized_Raw Volume',\n",
    "                                'Normalized_Local Corrected Volume', 'Normalized_Global Corrected Volume',\n",
    "                                'Background Corrected Volume', 'Normalized_Background Corrected Volume'],\n",
    "                    var_name='Variable', value_name='Volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66873c96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select rows based on the 'Variable' column\n",
    "selected_variables = ['Normalized_Local Corrected Volume', 'Normalized_Global Corrected Volume']\n",
    "#additional_column_value = 'GA'  # Replace with the specific value you want to filter on\n",
    "subset_df = melted_df[(melted_df['Variable'].isin(selected_variables))]\n",
    "#subset_df = melted_df[(melted_df['Variable'].isin(selected_variables)) & (melted_df['App'] == additional_column_value)]\n",
    "\n",
    "# Get unique values in the \"Gel ID\" column\n",
    "unique_gel_ids = concatenated_df['Gel ID'].unique()\n",
    "\n",
    "for gel_id in unique_gel_ids:\n",
    "    subset_df = melted_df[(melted_df['Variable'].isin(selected_variables)) & (melted_df['Gel ID'] == gel_id)]\n",
    "\n",
    "    # Plot the violin plot with log scale on the y-axis\n",
    "    sns.violinplot(data=subset_df, x='Lane ID', y='Volume', hue='Variable', split=True, inner='quart')\n",
    "\n",
    "    plt.title(f\"Gel - {gel_id}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ff258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select rows based on the 'Variable' column\n",
    "selected_variables = ['Normalized_Raw Volume']\n",
    "#additional_column_value = 'GA'  # Replace with the specific value you want to filter on\n",
    "subset_df = melted_df[(melted_df['Variable'].isin(selected_variables))]\n",
    "#subset_df = melted_df[(melted_df['Variable'].isin(selected_variables)) & (melted_df['App'] == additional_column_value)]\n",
    "\n",
    "# Get unique values in the \"Gel ID\" column\n",
    "unique_gel_ids = concatenated_df['Gel ID'].unique()\n",
    "\n",
    "for gel_id in unique_gel_ids:\n",
    "    subset_df = melted_df[(melted_df['Variable'].isin(selected_variables)) & (melted_df['Gel ID'] == gel_id)]\n",
    "\n",
    "    # Plot the violin plot with log scale on the y-axis\n",
    "    sns.violinplot(data=subset_df, x='Lane ID', y='Volume', hue='App', split=True, inner='quart', palette='muted')\n",
    "\n",
    "    plt.title(f\"Gel - {gel_id} - Normalised Raw Volume\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e884feb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select rows based on the 'Variable' column\n",
    "selected_variables = ['Normalized_Local Corrected Volume', 'Normalized_Global Corrected Volume', 'Normalized_Background Corrected Volume']\n",
    "#additional_column_value = 'GA'  # Replace with the specific value you want to filter on\n",
    "subset_df = melted_df[(melted_df['Variable'].isin(selected_variables))]\n",
    "#subset_df = melted_df[(melted_df['Variable'].isin(selected_variables)) & (melted_df['App'] == additional_column_value)]\n",
    "\n",
    "# Get unique values in the \"Gel ID\" column\n",
    "unique_gel_ids = concatenated_df['Gel ID'].unique()\n",
    "\n",
    "for gel_id in unique_gel_ids:\n",
    "    subset_df = melted_df[(melted_df['Variable'].isin(selected_variables)) & (melted_df['Gel ID'] == gel_id)]\n",
    "\n",
    "    # Plot the violin plot with log scale on the y-axis\n",
    "    sns.violinplot(data=subset_df, x='Lane ID', y='Volume', hue='Variable', palette='Set2', inner='quart')\n",
    "\n",
    "    plt.title(f\"Gel - {gel_id} - Normalised Volumes\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7714e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(concatenated_df, reference_df, on=['Band ID', 'Ladder'], how='left')\n",
    "merged_df['Expected Value'] = merged_df['Normalized_Intensity']\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26d6181",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"Raw Difference\"] = merged_df[\"Normalized_Raw Volume\"] - merged_df['Expected Value']\n",
    "merged_df[\"Local Difference\"] = merged_df[\"Normalized_Local Corrected Volume\"] - merged_df['Expected Value']\n",
    "merged_df[\"Global Difference\"] = merged_df[\"Normalized_Global Corrected Volume\"] - merged_df['Expected Value']\n",
    "merged_df[\"Background Difference\"] = merged_df[\"Normalized_Background Corrected Volume\"] - merged_df['Expected Value']\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930e0b9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Output PDF file path\n",
    "output_pdf_path = 'raw_plots.pdf'\n",
    "\n",
    "# Iterate over unique Gel IDs in merged_df and create separate plots\n",
    "unique_gel_ids = merged_df['Gel ID'].unique()\n",
    "\n",
    "with PdfPages(output_pdf_path) as pdf:\n",
    "    for gel_id in unique_gel_ids:\n",
    "        # Filter DataFrame for the current Gel ID\n",
    "        subset_df = merged_df[merged_df['Gel ID'] == gel_id]\n",
    "        \n",
    "        # Extract unique Band IDs\n",
    "        unique_band_ids = subset_df['Band ID'].unique()\n",
    "        \n",
    "        # Plot the results\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # List to store legends\n",
    "        legends = []\n",
    "        \n",
    "        # Iterate over unique values in the 'App' column\n",
    "        for app_value in subset_df['App'].unique():\n",
    "            # Calculate minimum and maximum Raw Difference per Band ID for each App\n",
    "            min_max_diff = subset_df[subset_df['App'] == app_value].groupby('Band ID')['Raw Difference'].agg(['min', 'max']).reset_index()\n",
    "            \n",
    "            # Plot lines for each App\n",
    "            for j, (band_id, row) in enumerate(min_max_diff.iterrows()):\n",
    "                # Choose linestyle and marker based on the 'App' column\n",
    "                linestyle = '--' if app_value == 'GA' else '-'\n",
    "                marker = 'o' if app_value == 'GG' else '^'\n",
    "                \n",
    "                # Set color based on 'App' column\n",
    "                color = 'red' if app_value == 'GG' else 'blue'\n",
    "                \n",
    "                line, = plt.plot(\n",
    "                    [row['min'], row['max']],\n",
    "                    [band_id, band_id],\n",
    "                    linestyle=linestyle,\n",
    "                    alpha=0.5,  # Set alpha to 0.5 for transparency\n",
    "                    marker=marker,\n",
    "                    color=color,\n",
    "                    label=f'{app_value} - Band ID {row[\"Band ID\"]}',\n",
    "                )\n",
    "                legends.append(line)\n",
    "        \n",
    "        plt.yticks(range(len(unique_band_ids)), unique_band_ids)  # Set y-axis ticks to unique Band IDs\n",
    "        plt.title(f'Min and Max Raw Difference per Band ID - Gel ID {gel_id}')\n",
    "        plt.xlabel('Raw Difference')\n",
    "        plt.ylabel('Band ID')\n",
    "        \n",
    "        # Add a green dashed vertical line at point 0\n",
    "        plt.axvline(x=0, color='green', linestyle='--', label='Zero Line')\n",
    "        \n",
    "        # Place the legend outside the plot to the right\n",
    "        plt.legend(handles=legends + [plt.Line2D([0], [0], color='green', linestyle='--')], bbox_to_anchor=(1.05, 1), loc='upper left', title='App')\n",
    "        \n",
    "        # Save the plot to the PDF file\n",
    "        pdf.savefig(bbox_inches='tight')  # Use bbox_inches='tight' to include the legend\n",
    "        plt.close()\n",
    "\n",
    "print(f'Plots saved to {output_pdf_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb118294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify the two columns for grouping\n",
    "group_columns = ['Local Difference', 'Global Difference']\n",
    "\n",
    "# Iterate over unique Gel IDs in merged_df and create separate plots\n",
    "unique_gel_ids = merged_df['Gel ID'].unique()\n",
    "\n",
    "for gel_id in unique_gel_ids:\n",
    "    # Filter DataFrame for the current Gel ID\n",
    "    subset_df = merged_df[merged_df['Gel ID'] == gel_id]\n",
    "    \n",
    "    # Extract unique Band IDs\n",
    "    unique_band_ids = subset_df['Band ID'].unique()\n",
    "    \n",
    "    # Plot the results for each Gel ID\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    legends = []\n",
    "\n",
    "    for i, band_id in enumerate(unique_band_ids):\n",
    "        # Filter DataFrame for the current Band ID\n",
    "        band_df = subset_df[subset_df['Band ID'] == band_id]\n",
    "\n",
    "        for j, column in enumerate(group_columns):\n",
    "            # Calculate minimum and maximum values for the current column\n",
    "            min_value = band_df[column].min()\n",
    "            max_value = band_df[column].max()\n",
    "\n",
    "            # Assign different markers and colors to the columns\n",
    "            markers = ['o', '^']\n",
    "            colors = ['red', 'blue']\n",
    "\n",
    "            # Plot lines for each column\n",
    "            linestyle = '--'\n",
    "            line, = plt.plot(\n",
    "                [min_value, max_value],\n",
    "                [band_id, band_id],\n",
    "                linestyle=linestyle,\n",
    "                alpha=0.5,\n",
    "                marker=markers[j],\n",
    "                color=colors[j],\n",
    "                label=f'{column} - Band ID {band_id}',\n",
    "            )\n",
    "            legends.append(line)\n",
    "\n",
    "    plt.title(f'Min and Max Values - Gel ID {gel_id}')\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Band ID')\n",
    "    \n",
    "    # Add a green dashed vertical line at point 0\n",
    "    plt.axvline(x=0, color='green', linestyle='--', label='Zero Line')\n",
    "\n",
    "    # Place the legend outside the plot to the right\n",
    "    plt.legend(handles=legends + [plt.Line2D([0], [0], color='green', linestyle='--')], bbox_to_anchor=(1.05, 1), loc='upper left', title='Legend')\n",
    "\n",
    "    # Display the plot for the current Gel ID\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392dfe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_min_max_values_to_pdf(df, group_columns, output_pdf_path='output_plots.pdf'):\n",
    "    # Extract unique Gel IDs\n",
    "    unique_gel_ids = df['Gel ID'].unique()\n",
    "\n",
    "    with PdfPages(output_pdf_path) as pdf:\n",
    "        for gel_id in unique_gel_ids:\n",
    "            # Filter DataFrame for the current Gel ID\n",
    "            subset_df = df[df['Gel ID'] == gel_id]\n",
    "\n",
    "            # Extract unique Band IDs\n",
    "            unique_band_ids = subset_df['Band ID'].unique()\n",
    "\n",
    "            # Plot the results for each Gel ID\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            legends = []\n",
    "\n",
    "            for i, band_id in enumerate(unique_band_ids):\n",
    "                # Filter DataFrame for the current Band ID\n",
    "                band_df = subset_df[subset_df['Band ID'] == band_id]\n",
    "\n",
    "                for j, column in enumerate(group_columns):\n",
    "                    # Calculate minimum and maximum values for the current column\n",
    "                    min_value = band_df[column].min()\n",
    "                    max_value = band_df[column].max()\n",
    "\n",
    "                    # Assign different markers and colors to the columns\n",
    "                    markers = ['o', '^']\n",
    "                    colors = ['red', 'blue']\n",
    "\n",
    "                    # Plot lines for each column\n",
    "                    linestyle = '--'\n",
    "                    line, = plt.plot(\n",
    "                        [min_value, max_value],\n",
    "                        [band_id, band_id],\n",
    "                        linestyle=linestyle,\n",
    "                        alpha=0.5,\n",
    "                        marker=markers[j],\n",
    "                        color=colors[j],\n",
    "                        label=f'{column} - Band ID {band_id}',\n",
    "                    )\n",
    "                    legends.append(line)\n",
    "\n",
    "            plt.title(f'Gel ID {gel_id}')\n",
    "            plt.xlabel('Values')\n",
    "            plt.ylabel('Band ID')\n",
    "\n",
    "            # Add a green dashed vertical line at point 0\n",
    "            plt.axvline(x=0, color='green', linestyle='--', label='Zero Line')\n",
    "\n",
    "            # Place the legend outside the plot to the right\n",
    "            plt.legend(handles=legends + [plt.Line2D([0], [0], color='green', linestyle='--')], bbox_to_anchor=(1.05, 1), loc='upper left', title='Legend')\n",
    "\n",
    "            # Save the plot to the PDF file\n",
    "            pdf.savefig(bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "    print(\"PDF Saved\")\n",
    "\n",
    "# Example usage:\n",
    "# Assuming merged_df is your DataFrame\n",
    "# plot_min_max_values_to_pdf(merged_df, group_columns=['Local Difference', 'Global Difference'], output_pdf_path='output_plots.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed5292",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_min_max_values_to_pdf(merged_df, group_columns=['Local Difference', 'Global Difference'], output_pdf_path='global-local.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_min_max_values_to_pdf(merged_df, group_columns=['Local Difference', 'Background Difference'], output_pdf_path='local-background.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f518e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_min_max_values_to_pdf(merged_df, group_columns=['Global Difference', 'Background Difference'], output_pdf_path='global-background.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg_rows = merged_df[merged_df['App'] == 'GG']\n",
    "ga_rows = merged_df[merged_df['App'] == 'GA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b6c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_min_max_values_to_pdf(ga_rows, group_columns=['Raw Difference', 'Background Difference'], output_pdf_path='ga_raw-background.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe6d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_min_max_values_to_pdf(gg_rows, group_columns=['Raw Difference', 'Local Difference'], output_pdf_path='gg_raw-local.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_min_max_values_to_pdf(gg_rows, group_columns=['Raw Difference', 'Global Difference'], output_pdf_path='gg_raw-global.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a446b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify the two columns for grouping\n",
    "group_columns = ['Local Difference', 'Global Difference', 'Background Difference']\n",
    "\n",
    "# Iterate over unique Gel IDs in merged_df and create separate plots\n",
    "unique_gel_ids = merged_df['Gel ID'].unique()\n",
    "\n",
    "for gel_id in unique_gel_ids:\n",
    "    # Filter DataFrame for the current Gel ID\n",
    "    subset_df = merged_df[merged_df['Gel ID'] == gel_id]\n",
    "    \n",
    "    # Extract unique Band IDs\n",
    "    unique_band_ids = subset_df['Band ID'].unique()\n",
    "    \n",
    "    # Plot the results for each Gel ID\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    legends = []\n",
    "\n",
    "    for i, band_id in enumerate(unique_band_ids):\n",
    "        # Filter DataFrame for the current Band ID\n",
    "        band_df = subset_df[subset_df['Band ID'] == band_id]\n",
    "\n",
    "        for j, column in enumerate(group_columns):\n",
    "            # Calculate minimum and maximum values for the current column\n",
    "            min_value = band_df[column].min()\n",
    "            max_value = band_df[column].max()\n",
    "\n",
    "            # Assign different markers and colors to the columns\n",
    "            markers = ['o', '^', '*']\n",
    "            colors = ['red', 'blue', 'purple']\n",
    "\n",
    "            # Plot lines for each column\n",
    "            linestyle = '--'\n",
    "            line, = plt.plot(\n",
    "                [min_value, max_value],\n",
    "                [band_id, band_id],\n",
    "                linestyle=linestyle,\n",
    "                alpha=0.5,\n",
    "                marker=markers[j],\n",
    "                color=colors[j],\n",
    "                label=f'{column} - Band ID {band_id}',\n",
    "            )\n",
    "            legends.append(line)\n",
    "\n",
    "    plt.title(f'Min and Max Values - Gel ID {gel_id}')\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Band ID')\n",
    "    \n",
    "    # Add a green dashed vertical line at point 0\n",
    "    plt.axvline(x=0, color='green', linestyle='--', label='Zero Line')\n",
    "\n",
    "    # Place the legend outside the plot to the right\n",
    "    plt.legend(handles=legends + [plt.Line2D([0], [0], color='green', linestyle='--')], bbox_to_anchor=(1.05, 1), loc='upper left', title='Legend')\n",
    "\n",
    "    # Display the plot for the current Gel ID\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818b41e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Specify the two columns for grouping\n",
    "group_columns = ['Local Difference', 'Global Difference', 'Background Difference']\n",
    "\n",
    "# Iterate over unique Gel IDs in merged_df and create separate plots\n",
    "unique_gel_ids = merged_df['Gel ID'].unique()\n",
    "\n",
    "for gel_id in unique_gel_ids:\n",
    "    # Filter DataFrame for the current Gel ID\n",
    "    subset_df = merged_df[merged_df['Gel ID'] == gel_id]\n",
    "    \n",
    "    # Extract unique Band IDs\n",
    "    unique_band_ids = subset_df['Band ID'].unique()\n",
    "    \n",
    "    # Plot the results for each Gel ID\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    legends = []\n",
    "\n",
    "    for i, band_id in enumerate(unique_band_ids):\n",
    "        # Filter DataFrame for the current Band ID\n",
    "        band_df = subset_df[subset_df['Band ID'] == band_id]\n",
    "\n",
    "        for j, column in enumerate(group_columns):\n",
    "            # Calculate average value for the current column\n",
    "            avg_value = band_df[column].mean()\n",
    "\n",
    "            # Calculate standard deviation for error bars\n",
    "            std_dev = band_df[column].std()\n",
    "\n",
    "            # Assign different markers and colors to the columns\n",
    "            markers = ['o', '^', '*']\n",
    "            colors = ['red', 'blue', 'purple']\n",
    "\n",
    "            # Plot lines and error bars for each column\n",
    "            linestyle = '--'\n",
    "            line = plt.errorbar(\n",
    "                avg_value,\n",
    "                band_id,\n",
    "                xerr=std_dev,\n",
    "                linestyle=linestyle,\n",
    "                alpha=0.5,\n",
    "                marker=markers[j],\n",
    "                color=colors[j],\n",
    "                label=f'{column} - Band ID {band_id}',\n",
    "            )\n",
    "            legends.append(line)\n",
    "\n",
    "    plt.title(f'Average Values with Error Bars - Gel ID {gel_id}')\n",
    "    plt.xlabel('Average Values')\n",
    "    plt.ylabel('Band ID')\n",
    "    \n",
    "    # Set y-axis ticks to unique Band IDs\n",
    "    plt.yticks(unique_band_ids)\n",
    "    \n",
    "    # Reverse the y-axis\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # Add a green dashed vertical line at point 0\n",
    "    plt.axvline(x=0, color='green', linestyle='--', label='Zero Line')\n",
    "\n",
    "    # Place the legend outside the plot to the right\n",
    "    plt.legend(handles=legends + [plt.Line2D([0], [0], color='green', linestyle='--')], bbox_to_anchor=(1.05, 1), loc='upper left', title='Legend')\n",
    "\n",
    "    # Display the plot for the current Gel ID\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f6a6d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split the DataFrame based on 'App' values\n",
    "df_gg = merged_df[merged_df['App'] == 'GG'].copy()\n",
    "df_ga = merged_df[merged_df['App'] == 'GA'].copy()\n",
    "\n",
    "# Rename the 'Raw Difference' column in each filtered DataFrame\n",
    "df_gg.rename(columns={'Raw Difference': 'Raw Difference_GG'}, inplace=True)\n",
    "df_ga.rename(columns={'Raw Difference': 'Raw Difference_GA'}, inplace=True)\n",
    "\n",
    "# Merge the filtered DataFrames back together using outer join\n",
    "result_df = pd.merge(df_gg[['Lane ID', 'Band ID', 'Raw Difference_GG']], df_ga[['Lane ID', 'Band ID', 'Raw Difference_GA']], on=['Lane ID', 'Band ID'], how='outer')\n",
    "\n",
    "# Merge the combined result with the original DataFrame\n",
    "result_df = pd.merge(merged_df, result_df, on=['Lane ID', 'Band ID'], how='left')\n",
    "\n",
    "# Displaying the modified DataFrame\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d6604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
