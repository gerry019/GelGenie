{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b45bdfac-e871-44ce-8bd6-d693b47274c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import re\n",
    "from gelgenie.segmentation.helper_functions.general_functions import create_dir_if_empty, index_converter\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import math\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9148cb1f-674e-42a4-a6b8-3dac490bbb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update your paths here\n",
    "gg_path = Path(\"/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/quantitative_results/qupath_data/james_data_v3_fixed_global/Data_with_norm_and_corrections\")\n",
    "ga_path = Path(\"/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/quantitative_results/gelanalyzer\")\n",
    "reference_path = Path(\"/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/quantitative_results/reference_ladder_masses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1122b9a3-f4e7-4bc7-9aee-3e98f1f2c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_ladder_names_from_files(folder_path):\n",
    "    \"\"\"\n",
    "    Reads in and assigns each gel a ladder type\n",
    "    \"\"\"\n",
    "    ladder_dict = {}  \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_number = int(filename.split(\"_\")[0])\n",
    "            ladder_name = filename.split(\"_\")[1]\n",
    "            ladder_dict[file_number] = ladder_name\n",
    "    return ladder_dict\n",
    "\n",
    "def load_gg_csv_files_to_dict(folder_path, prefix=\"prefix_\"):\n",
    "    \"\"\"\n",
    "    Load CSV files from a folder and create a dictionary of DataFrames with prefixed keys.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): The path to the folder containing CSV files.\n",
    "    - prefix (str): The prefix to be added to the keys of the dictionary (default is \"prefix_\").\n",
    "\n",
    "    Returns:\n",
    "    - dataframes_dict (dict): A dictionary where keys are prefixed numbers, and values are corresponding DataFrames.\n",
    "    \"\"\"\n",
    "    dataframes_dict = {}  # Dictionary to store DataFrames\n",
    "\n",
    "    # Iterate through files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file is a CSV file\n",
    "        if filename.endswith(\".csv\"):\n",
    "            # Extract the number from the filename\n",
    "            file_number = filename.split(\"_\")[0]\n",
    "\n",
    "            # Read the CSV file into a DataFrame\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            dataframe = pd.read_csv(file_path)\n",
    "\n",
    "            # Add the prefix to the number and use it as the key in the dictionary\n",
    "            key = f\"{prefix}{file_number}\"\n",
    "            dataframes_dict[key] = dataframe\n",
    "\n",
    "    return dataframes_dict\n",
    "def load_ga_csv_files_from_folders(parent_folder, prefix=\"ga_\"):\n",
    "    \"\"\"\n",
    "    Load CSV files from folders and create a dictionary of DataFrames with prefixed names.\n",
    "\n",
    "    Parameters:\n",
    "    - parent_folder (str): The path to the parent folder containing numbered subfolders.\n",
    "    - prefix (str): The prefix to be added to the names of the DataFrames (default is \"ga_\").\n",
    "\n",
    "    Returns:\n",
    "    - dataframes (dict): A dictionary where keys are prefixed folder names, and values are corresponding DataFrames.\n",
    "    \"\"\"\n",
    "    dataframes = {}  # Dictionary to store DataFrames\n",
    "\n",
    "    # Iterate through folders in the parent folder\n",
    "    for folder_name in os.listdir(parent_folder):\n",
    "        folder_path = os.path.join(parent_folder, folder_name)\n",
    "\n",
    "        # Check if the item in the parent folder is a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            csv_file_path = os.path.join(folder_path, \"collated_data_with_band_quality.csv\")\n",
    "\n",
    "            # Check if \"collated_data_with_band_quality.csv\" exists in the folder\n",
    "            if os.path.isfile(csv_file_path):\n",
    "                # Read the CSV file into a DataFrame\n",
    "                dataframe = pd.read_csv(csv_file_path)\n",
    "                dataframe = dataframe.rename(columns={'Raw Volume':'GA-Raw-Vol', 'Background Corrected Volume':'GA-BC-Vol'})\n",
    "\n",
    "                # Add the prefix to the folder name and use it as the key in the dictionary\n",
    "                prefixed_folder_name = f\"{prefix}{folder_name}\"\n",
    "                dataframes[prefixed_folder_name] = dataframe\n",
    "\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15719690-ddef-4920-9843-4439053f2350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads in GG data\n",
    "gg_dfs = load_gg_csv_files_to_dict(gg_path, \"gg_\") # loads data and converts to dictionary\n",
    "gg_dfs = {key: gg_dfs[key] for key in sorted(gg_dfs.keys(), key=lambda s: [int(t) if t.isdigit() else t.lower() for t in re.split(r'(\\d+)', s)])}  # sorts by gel ID\n",
    "\n",
    "# loads in GA data\n",
    "ga_dfs = load_ga_csv_files_from_folders(ga_path)\n",
    "ga_dfs = {key: ga_dfs[key] for key in sorted(ga_dfs.keys(), key=lambda s: [int(t) if t.isdigit() else t.lower() for t in re.split(r'(\\d+)', s)])} # sorts by gel ID\n",
    "\n",
    "# loads in ladder values\n",
    "ladder_dict = identify_ladder_names_from_files(gg_path)\n",
    "\n",
    "# reads in, combines and formats ladder reference mass values\n",
    "reference_df = pd.read_csv(reference_path)\n",
    "reference_df.rename(columns={\"NEB ladder\": \"NEB\", \" ThermoFisher ladder\": \"Thermo\"}, inplace=True)\n",
    "reference_df[\"Band ID\"] = range(1, len(reference_df) + 1)\n",
    "reference_df = pd.melt(reference_df, id_vars=[\"Band ID\"], value_vars=[\"NEB\", \"Thermo\"], var_name=\"Ladder\", value_name=\"Intensity\")\n",
    "reference_df['Normalized_Intensity'] = reference_df.groupby(\"Ladder\")[\"Intensity\"].transform(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de382ca-28b6-4e79-9c59-b89e3046045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 removes bands from both gg and ga that have the low quality mark from ga\n",
    "#2 removes bands that are not present in both ga and gg\n",
    "#3 gels 28 and 30 have been completely excluded from analysis as bands cannot be identified properly (done prior to this notebook)\n",
    "#4 combines all data into a single dataframe for each gel\n",
    "# gels 25,26,27 are also screwing up the analysis as their lower bands are more bleached than the top ones, removing for now\n",
    "origin_data = {} # this contains the combined GA and GG data\n",
    "for key, df in ga_dfs.items():\n",
    "    id = int(key.split('_')[-1])\n",
    "    if id in [25,26,27]:\n",
    "        continue\n",
    "    dfgg =  gg_dfs['gg_%s' % id]\n",
    "    merged_df = pd.merge(df, dfgg, on=['Lane ID', 'Band ID'])\n",
    "    filtered_df = merged_df[merged_df['Reliable Band'] == 1]\n",
    "    origin_data[id] = filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7be37987-36e6-4e91-bb86-89b375ad6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bins each band in terms of rectangularity i.e. how rectangular a band is, intensity and background intensity (calculated from the background found by the local background detection system)\n",
    "# Each 'Cat_' column contains the categorised value for all 3 quantities\n",
    "# TODO: check that everything is worked properly as intended here, and see if any hardcoded values can be removed\n",
    "bin_count = 15\n",
    "for key, val in origin_data.items():\n",
    "    val['Rectangularity'] = val['Pixel Count']/(val['Width']*val['Height'])\n",
    "    val['Cat_Rectangularity'] = pd.cut(val['Rectangularity'], bins=bin_count, labels=False)\n",
    "    if key in [29,30]: # 16-bit images\n",
    "        val['Rel.A. Intensity'] = val['Average Intensity']/65535\n",
    "        val['Rel.S. Intensity'] = val['Intensity SD']/65535\n",
    "    else:\n",
    "        val['Rel.A. Intensity'] = val['Average Intensity']/255\n",
    "        val['Rel.S. Intensity'] = val['Intensity SD']/255\n",
    "    \n",
    "    val['Background Level'] = (val['Raw Volume'] - val['Local Corrected Volume'])/(val['Raw Volume'])\n",
    "\n",
    "    val['Cat_Intensity'] = pd.cut(val['Rel.A. Intensity'], bins=bin_count, labels=False)\n",
    "    \n",
    "    val['Cat_Range'] = pd.cut(val['Rel.S. Intensity'], bins=bin_count, labels=False)\n",
    "\n",
    "    val['Cat_Background'] = pd.cut(val['Background Level'], bins=bin_count, labels=False)\n",
    "\n",
    "    # print(key, val['Rel.A. Intensity'].max(), val['Rel.S. Intensity'].max(), val['Background Level'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7eec8ea2-8139-492f-a363-d8473878ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ce4ac7-021c-4987-ba82-453601d53859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for adaptive normalisation\n",
    "def norm_by_lane(df, norm_col, lane_col = 'Lane ID', max_only=False):\n",
    "    \"\"\"\n",
    "    Direct min-max normalisation, grouped by the Lane ID\n",
    "    \"\"\"\n",
    "\n",
    "    min_values = df.groupby(lane_col)[norm_col].transform('min')\n",
    "    max_values = df.groupby(lane_col)[norm_col].transform('max')\n",
    "\n",
    "    if max_only:\n",
    "        return df[norm_col]/max_values\n",
    "    else:\n",
    "        return (df[norm_col] - min_values)/(max_values-min_values)\n",
    "    \n",
    "def adaptive_normalisation(data_dict, ladder_dict, columns_to_extract, max_only=False):\n",
    "    \"\"\"\n",
    "    Since some lanes have bands missing, the ladder normalisation needs to be re-calculated to match the number of bands available.\n",
    "    This function runs the adaptive normalisation and fuses the reference ladder data with the band data.\n",
    "    \"\"\"\n",
    "    temp_combo_df = origin_data[gelid][columns_to_extract].copy()\n",
    "    temp_combo_df['Reference Value'] = 0.0\n",
    "    for lane in data_dict['Lane ID'].unique():\n",
    "        \n",
    "        available_bands = data_dict[data_dict['Lane ID'] == lane]['Band ID'].unique()\n",
    "        ladder_crop = ladder_dict[ladder_dict['Band ID'].isin(available_bands)].copy() # only retain the bands that are available in the data\n",
    "        # usual norm here\n",
    "        min_value = ladder_crop['Reference Value'].min()\n",
    "        max_value = ladder_crop['Reference Value'].max()\n",
    "        if max_only:            \n",
    "            ladder_crop['Reference Value'] = ladder_crop['Reference Value'] / max_value\n",
    "        else:\n",
    "            ladder_crop['Reference Value'] = (ladder_crop['Reference Value'] - min_value) / (max_value - min_value)\n",
    "        # (value)/(maximum) - result is a value between 0 0.2 and 1\n",
    "        # 0 -0.3  2 3 4 5 5 6 7\n",
    "        ladder_crop['Lane ID'] = lane\n",
    "        \n",
    "        # combine data together here\n",
    "        temp_combo_df.set_index(['Lane ID', 'Band ID'], inplace=True)\n",
    "        ladder_crop.set_index(['Lane ID', 'Band ID'], inplace=True)\n",
    "\n",
    "        temp_combo_df.update(ladder_crop['Reference Value'])\n",
    "        # Reset the indices to make them regular columns\n",
    "        temp_combo_df.reset_index(inplace=True)\n",
    "        ladder_crop.reset_index(inplace=True)\n",
    "  \n",
    "    return temp_combo_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "89939a9c-d4de-460e-96e7-9d1dbc29bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "33363690-b6b4-4a9a-9914-ceed87f9a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per gel boxplots, categorised by one of the binned values generated earlier\n",
    "# TODO: how are there so many high-error values?  Need to investigate the adaptive normalisation\n",
    "selected_gels = [13]\n",
    "target_x = 'Cat_Rectangularity'\n",
    "quantities = ['GA-Raw-Vol', 'GA-BC-Vol','Raw Volume', 'Rolling Ball Corrected Volume', 'Global Corrected Volume', 'Local Corrected Volume']\n",
    "\n",
    "all_bins = range(15)\n",
    "max_only = True\n",
    "for gelid in selected_gels:\n",
    "    ref_vals = reference_df[reference_df['Ladder'] == ladder_dict[gelid]] # extract the ladder related to the selected gel\n",
    "    ref_vals = ref_vals.drop(columns=['Ladder', 'Normalized_Intensity'])\n",
    "    ref_vals.rename(columns={'Intensity':'Reference Value'},inplace=True)\n",
    "    columns_to_extract = ['Lane ID', 'Band ID', 'Rectangularity', target_x]\n",
    "    temp_combo_df = adaptive_normalisation(origin_data[gelid], ref_vals, columns_to_extract, max_only=max_only) # run adaptive norm on ladder\n",
    "\n",
    "    for index, quantity in enumerate(quantities): # calculate error quantities\n",
    "        \n",
    "        quant_data = norm_by_lane(origin_data[gelid], quantity, max_only=max_only).reset_index(drop=True)\n",
    "        temp_combo_df[quantity] = quant_data\n",
    "        temp_combo_df['E-%s' % quantity] = np.abs(temp_combo_df['Reference Value']-quant_data)\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    # melts data for plotting\n",
    "    df_melted = pd.melt(temp_combo_df, id_vars=[target_x], \n",
    "                        value_vars=['E-GA-Raw-Vol', 'E-GA-BC-Vol', 'E-Raw Volume', 'E-Rolling Ball Corrected Volume'], \n",
    "                        var_name='Values')\n",
    "    \n",
    "    ax = sns.boxplot(x=target_x, y='value', hue='Values', data=df_melted, width=0.5,order=all_bins)\n",
    "    x_label = []\n",
    "    # Adds text annotations for the number of instances in each boxplot\n",
    "    for category in all_bins:\n",
    "        num_instances = len(temp_combo_df[temp_combo_df[target_x] == category])\n",
    "        x_label.append('%s (%s)' % (category, num_instances))\n",
    "    ax.set_xticks(ax.get_xticks());\n",
    "    ax.set_xticklabels(x_label)\n",
    "    plt.title('Gel %s' % gelid)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b5cd070e-c706-4ebc-965f-0f9ff12769d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_combo_df[temp_combo_df['Lane ID'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04226b75-5586-4e11-9227-ae0cee7aa17c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a0b770ca-02d7-4750-807f-14868b877db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "scatter_size = 1.5\n",
    "target_quant = 'Background Level'\n",
    "\n",
    "colorwheel = ['blue', 'red', 'green', 'orange', 'purple', 'black']\n",
    "\n",
    "\n",
    "# Plot each line\n",
    "plt.scatter(temp_combo_df[target_quant], temp_combo_df['E-GA-Raw-Vol'], label='GA-Raw',s=scatter_size, c=colorwheel[0])\n",
    "plt.scatter(temp_combo_df[target_quant], temp_combo_df['E-GA-BC-Vol'], label='GA-BG',s=scatter_size, c=colorwheel[1])\n",
    "# plt.scatter(temp_combo_df[target_quant], temp_combo_df['E-Raw Volume'], label='GG-Raw',s=scatter_size, c=colorwheel[2])\n",
    "# plt.scatter(temp_combo_df[target_quant], temp_combo_df['E-Rolling Ball Corrected Volume'], label='GG-RB',s=scatter_size, c=colorwheel[3])\n",
    "# plt.scatter(temp_combo_df[target_quant], temp_combo_df['E-Global Corrected Volume'], label='GG-GB',s=scatter_size, c=colorwheel[4])\n",
    "# plt.scatter(temp_combo_df[target_quant], temp_combo_df['E-Local Corrected Volume'], label='GG-LB',s=scatter_size, c=colorwheel[5])\n",
    "\n",
    "\n",
    "# Fit lines\n",
    "# for index, column in enumerate(['E-GA-Raw-Vol', 'E-GA-BC-Vol', 'E-Raw Volume', 'E-Rolling Ball Corrected Volume', 'E-Global Corrected Volume', 'E-Local Corrected Volume']):\n",
    "#     slope, intercept, rval, _, _ = linregress(temp_combo_df[target_quant], temp_combo_df[column])\n",
    "#     print(f'Rval for {column} is {rval}')\n",
    "#     plt.plot(temp_combo_df[target_quant], slope * temp_combo_df[target_quant] + intercept, linestyle='--', color=colorwheel[index])\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel(target_quant)\n",
    "plt.ylabel('Error')\n",
    "plt.title('Line Graph with Multiple Columns')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd77fe4-1e5e-4895-9ce9-7053a4f21926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b11ed3c7-8e9f-460b-8492-0dd93af75125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full dataset boxplots\n",
    "# TODO: Again, why are there so many high error values?  Something must be going wrong with the adaptive normalisation\n",
    "selected_gels = origin_data.keys()\n",
    "quantities = ['GA-Raw-Vol', 'GA-BC-Vol','Raw Volume', 'Rolling Ball Corrected Volume', 'Global Corrected Volume', 'Local Corrected Volume']\n",
    "all_bins = range(15)\n",
    "\n",
    "target_x = ['Cat_Range', 'Cat_Intensity', 'Cat_Rectangularity', 'Cat_Background']\n",
    "max_only = True\n",
    "\n",
    "for g_index, gelid in enumerate(selected_gels):\n",
    "    ref_vals = reference_df[reference_df['Ladder'] == ladder_dict[gelid]]\n",
    "    ref_vals = ref_vals.drop(columns=['Ladder', 'Normalized_Intensity'])\n",
    "    ref_vals.rename(columns={'Intensity':'Reference Value'},inplace=True)\n",
    "    columns_to_extract = ['Lane ID', 'Band ID', 'Rectangularity', 'Background Level']\n",
    "    columns_to_extract.extend(target_x)\n",
    "    # combines all data into a single big dataframe here\n",
    "    if g_index == 0:\n",
    "        temp_combo_df = adaptive_normalisation(origin_data[gelid].reset_index(), ref_vals, columns_to_extract, max_only=max_only)\n",
    "        temp_combo_df['Gel ID'] = gelid\n",
    "        for index, quantity in enumerate(quantities):\n",
    "            quant_data = norm_by_lane(origin_data[gelid], quantity, max_only=max_only).reset_index(drop=True)\n",
    "            temp_combo_df[quantity] = quant_data\n",
    "            temp_combo_df['E-%s' % quantity] = np.abs(temp_combo_df['Reference Value']-quant_data)\n",
    "    else:\n",
    "        tdf2 = adaptive_normalisation(origin_data[gelid].reset_index(), ref_vals, columns_to_extract, max_only=max_only)\n",
    "        tdf2['Gel ID'] = gelid\n",
    "        for index, quantity in enumerate(quantities):\n",
    "            quant_data = norm_by_lane(origin_data[gelid], quantity, max_only=max_only).reset_index(drop=True)\n",
    "            tdf2[quantity] = quant_data\n",
    "            tdf2['E-%s' % quantity] = np.abs(tdf2['Reference Value']-quant_data)\n",
    "        temp_combo_df = pd.concat([temp_combo_df, tdf2], ignore_index=True)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "ax = sns.boxplot(data=temp_combo_df[['E-%s' % x for x in quantities]])\n",
    "plt.title('Entire Dataset (%s bands)' % len(temp_combo_df))\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/Users/matt/Desktop/full_dataset_plot.png', dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(temp_combo_df[['E-%s' % x for x in quantities]].mean())\n",
    "\n",
    "for tx in target_x:\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    # melts data for plotting\n",
    "    df_melted = pd.melt(temp_combo_df, id_vars=tx, value_vars=['E-GA-Raw-Vol', 'E-GA-BC-Vol', 'E-Raw Volume', 'E-Rolling Ball Corrected Volume',\n",
    "                                                              'E-Global Corrected Volume', 'E-Local Corrected Volume'], var_name='Values')\n",
    "    ax = sns.boxplot(x=tx, y='value', hue='Values', data=df_melted, width=0.5,order=all_bins)\n",
    "    \n",
    "    x_label = []\n",
    "    # Adds text annotations for the number of instances in each boxplot\n",
    "    for category in all_bins:\n",
    "        num_instances = len(temp_combo_df[temp_combo_df[tx] == category])\n",
    "        x_label.append('%s (%s)' % (category, num_instances))\n",
    "    ax.set_xticks(ax.get_xticks())\n",
    "    ax.set_xticklabels(x_label)   \n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('/Users/matt/Desktop/%s_gel_plot.png' % tx, dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75507caa-8296-4db7-a4c7-2fb5aba98e8a",
   "metadata": {},
   "source": [
    "## Testing new Analysis Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "097ad8ef-7a09-43f5-ae17-7cf3e3f8a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_df = pickle.load(open('/Users/matt/Desktop/full_dataset.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "640bf263-443b-4253-960a-c0189bb018ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = '29_NEB'\n",
    "sel_df = correl_df[data_name]\n",
    "\n",
    "figs_per_row = 3\n",
    "rows = math.ceil((len(np.unique(sel_df['Lane ID']) + 1) / figs_per_row))\n",
    "if rows == 1:\n",
    "    double_indexing = False\n",
    "else:\n",
    "    double_indexing = True\n",
    "\n",
    "fig, ax = plt.subplots(rows, figs_per_row, figsize=(18, 15))\n",
    "\n",
    "all_corr_coeff = {}\n",
    "color_wheel = ['b', 'g', 'r', 'k', 'yellow', 'purple', 'orange', 'lilac', 'yellow', 'steelblue']\n",
    "plot_col_index = 0\n",
    "for col_index, column in enumerate(sel_df.columns):\n",
    "    if column == 'Lane ID' or column == 'Band ID' or column == 'Ref.':\n",
    "        continue\n",
    "    for lane in np.unique(sel_df['Lane ID']):\n",
    "        ref = sel_df[sel_df['Lane ID'] == lane]['Ref.']\n",
    "        target = sel_df[sel_df['Lane ID'] == lane][column]\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(ref, target)\n",
    "        ax[index_converter(lane-1, figs_per_row, double_indexing)].scatter(\n",
    "                             sel_df[sel_df['Lane ID'] == lane]['Ref.'],\n",
    "                             sel_df[sel_df['Lane ID'] == lane][column],\n",
    "                             label=f'{column}, R2: {r_value**2:.3f}', c=color_wheel[plot_col_index])\n",
    "\n",
    "        ref_plot = np.linspace(np.min(ref), np.max(ref), num=10)\n",
    "        ax[index_converter(lane-1, figs_per_row, double_indexing)].plot(ref_plot, slope * ref_plot + intercept, color=color_wheel[plot_col_index], linestyle='dotted')\n",
    "        ax[index_converter(lane-1, figs_per_row, double_indexing)].legend()\n",
    "        ax[index_converter(lane - 1, figs_per_row, double_indexing)].set_title(f'Lane {lane}')\n",
    "        ax[index_converter(lane - 1, figs_per_row, double_indexing)].set_yscale('log')\n",
    "\n",
    "    plot_col_index += 1\n",
    "plt.suptitle(data_name)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4188d4d7-85f9-459b-80e5-d42acf02ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def hidden_linreg(target, ref, num_hide=3, num_reps=10):\n",
    "\n",
    "    # Initialize an empty list to store the selected sets\n",
    "    selected_sets = set()\n",
    "    \n",
    "    # Loop to select unique sets\n",
    "    for _ in range(num_reps):\n",
    "        # Select the first 3 numbers as a set\n",
    "        selected_set = tuple(np.random.choice(range(len(target)), num_hide, replace=False))\n",
    "        # Check if the set is already selected\n",
    "        while selected_set in selected_sets:\n",
    "            selected_set = tuple(np.random.choice(range(len(target)), num_hide, replace=False))\n",
    "        selected_sets.add(selected_set)\n",
    "\n",
    "    errors = []\n",
    "    for combo in selected_sets:\n",
    "        tfrac, rfrac = [t for ind, t in enumerate(target) if ind not in combo], [r for ind, r in enumerate(ref) if ind not in combo]\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(tfrac, rfrac)\n",
    "        pred = [slope * target[sel_ind] + intercept for sel_ind in combo]\n",
    "        tsel = [ref[sel_ind] for sel_ind in combo]\n",
    "        errors.append(np.average([np.abs(t-p) for t,p in zip(tsel,pred)]))\n",
    "    return errors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "744e74b5-bcf5-487f-8f96-6eb37708e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_linreg([1,2,3,4,5,6,7], [1,2,3,4,9,6,8], 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502bb8e4-4e85-47d0-be0a-ef5bf5d30614",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_per_row = 3\n",
    "rows = math.ceil((len(np.unique(sel_df['Lane ID']) + 1) / figs_per_row))\n",
    "if rows == 1:\n",
    "    double_indexing = False\n",
    "else:\n",
    "    double_indexing = True\n",
    "\n",
    "all_corr_coeff = {}\n",
    "correl_dict = defaultdict(list)\n",
    "\n",
    "for big_key in correl_df.keys():\n",
    "    sel_df = correl_df[big_key]\n",
    "    for col_index, column in enumerate(sel_df.columns):\n",
    "        if column == 'Lane ID' or column == 'Band ID' or column == 'Ref.':\n",
    "            continue\n",
    "        for lane in np.unique(sel_df['Lane ID']):\n",
    "            ref = sel_df[sel_df['Lane ID'] == lane]['Ref.']\n",
    "            target = sel_df[sel_df['Lane ID'] == lane][column]\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(ref, target)\n",
    "            correl_dict[column].append(r_value**2)\n",
    "        \n",
    "rsquared_df = pd.DataFrame.from_dict(correl_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e490b3b3-ace6-4eca-8fec-8d91976bd6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_per_row = 3\n",
    "rows = math.ceil((len(np.unique(sel_df['Lane ID']) + 1) / figs_per_row))\n",
    "if rows == 1:\n",
    "    double_indexing = False\n",
    "else:\n",
    "    double_indexing = True\n",
    "\n",
    "all_corr_coeff = {}\n",
    "correl_dict = defaultdict(list)\n",
    "\n",
    "for big_key in correl_df.keys():\n",
    "    sel_df = correl_df[big_key]\n",
    "    for col_index, column in enumerate(sel_df.columns):\n",
    "        if column == 'Lane ID' or column == 'Band ID' or column == 'Ref.':\n",
    "            continue\n",
    "        for lane in np.unique(sel_df['Lane ID']):\n",
    "            ref = sel_df[sel_df['Lane ID'] == lane]['Ref.']\n",
    "            target = sel_df[sel_df['Lane ID'] == lane][column]\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(ref, target)\n",
    "            correl_dict[column].append(r_value**2)\n",
    "        \n",
    "rsquared_df = pd.DataFrame.from_dict(correl_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7be64b24-1e2e-448c-8ab8-563b21ae9dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(data=rsquared_df, width=0.5)\n",
    "ax.tick_params(axis='x', rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f30bd2a-d232-4a98-a699-9d6cb42c6c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_per_row = 3\n",
    "rows = math.ceil((len(np.unique(sel_df['Lane ID']) + 1) / figs_per_row))\n",
    "if rows == 1:\n",
    "    double_indexing = False\n",
    "else:\n",
    "    double_indexing = True\n",
    "\n",
    "all_corr_coeff = {}\n",
    "\n",
    "gel_sets = [['0_Thermo','1_Thermo','2_Thermo','3_Thermo','4_Thermo'],\n",
    "           ['5_Thermo','6_Thermo','7_Thermo','8_Thermo'],\n",
    "           ['9_Thermo','10_Thermo','11_Thermo','12_Thermo'],\n",
    "           ['14_NEB', '17_NEB', '16_NEB'],\n",
    "           ['13_NEB', '15_NEB'],\n",
    "           ['18_NEB', '19_NEB', '20_NEB'],\n",
    "           ['21_NEB', '22_NEB', '23_NEB', '24_NEB'],\n",
    "           ['29_NEB'],\n",
    "           ['31_NEB'],\n",
    "           ['32_Thermo'],\n",
    "           ['33_NEB'],\n",
    "           ['34_Thermo']]\n",
    "\n",
    "for gel_set in gel_sets:\n",
    "    correl_dict = defaultdict(list)\n",
    "    for big_key in gel_set:\n",
    "        sel_df = correl_df[big_key]\n",
    "        for col_index, column in enumerate(sel_df.columns):\n",
    "            if column == 'Lane ID' or column == 'Band ID' or column == 'Ref.':\n",
    "                continue\n",
    "            for lane in np.unique(sel_df['Lane ID']):\n",
    "                ref = sel_df[sel_df['Lane ID'] == lane]['Ref.']\n",
    "                target = sel_df[sel_df['Lane ID'] == lane][column]\n",
    "                slope, intercept, r_value, p_value, std_err = linregress(ref, target)\n",
    "                correl_dict[column].append(r_value**2)\n",
    "        \n",
    "    rsquared_df = pd.DataFrame.from_dict(correl_dict)\n",
    "    plt.figure()\n",
    "    ax = sns.boxplot(data=rsquared_df, width=0.5)\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "778501c4-bddc-4773-9355-8df32aab052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_per_row = 3\n",
    "rows = math.ceil((len(np.unique(sel_df['Lane ID']) + 1) / figs_per_row))\n",
    "if rows == 1:\n",
    "    double_indexing = False\n",
    "else:\n",
    "    double_indexing = True\n",
    "\n",
    "all_corr_coeff = {}\n",
    "\n",
    "gel_sets = [['0_Thermo','1_Thermo','2_Thermo','3_Thermo','4_Thermo'],\n",
    "           ['5_Thermo','6_Thermo','7_Thermo','8_Thermo'],\n",
    "           ['9_Thermo','10_Thermo','11_Thermo','12_Thermo']]\n",
    "\n",
    "for big_key in gel_sets[2]:\n",
    "    sel_df = correl_df[big_key]\n",
    "    correl_dict = defaultdict(list)\n",
    "    for col_index, column in enumerate(sel_df.columns):\n",
    "        if column == 'Lane ID' or column == 'Band ID' or column == 'Ref.':\n",
    "            continue\n",
    "        for lane in np.unique(sel_df['Lane ID']):\n",
    "            ref = sel_df[sel_df['Lane ID'] == lane]['Ref.']\n",
    "            target = sel_df[sel_df['Lane ID'] == lane][column]\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(ref, target)\n",
    "            correl_dict[column].append(r_value**2)\n",
    "    \n",
    "    rsquared_df = pd.DataFrame.from_dict(correl_dict)\n",
    "    plt.figure()\n",
    "    ax = sns.boxplot(data=rsquared_df, width=0.5)\n",
    "    ax.tick_params(axis='x', rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ae90c7-64dd-4f87-9296-500f6c23dfd0",
   "metadata": {},
   "source": [
    "### JUST TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42629768-0e87-4636-aa02-fc622f0298ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_gels = [6]\n",
    "ladder = 'Thermo'\n",
    "ref_vals = reference_df[reference_df['Ladder'] == ladder]\n",
    "ref_vals = ref_vals.drop(columns=['Ladder', 'Intensity'])\n",
    "ref_vals.rename(columns={'Normalized_Intensity':'Reference Value'},inplace=True)\n",
    "for gelid in selected_gels:\n",
    "    dfi = {'GG':gg_dfs['gg_%d' % gelid], \n",
    "           'GA': ga_dfs['ga_%d' % gelid]}\n",
    "    \n",
    "    quantities = ['Raw Volume', 'Raw Volume', 'Background Corrected Volume', 'Rolling Ball Corrected Volume', 'Global Corrected Volume', 'Local Corrected Volume']\n",
    "    abbrvs = ['GG', 'GA', 'GA', 'GG', 'GG', 'GG']\n",
    "    columns_to_extract = ['Lane ID', 'Band ID']\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    temp_combo_df = gg_dfs['gg_%d' % gelid][columns_to_extract].copy()\n",
    "    temp_combo_df = pd.merge(temp_combo_df, ref_vals, on=['Band ID'], how='left')\n",
    "    \n",
    "    for index, (quantity, abbrv) in enumerate(zip(quantities, abbrvs)):\n",
    "        quant_data = norm_by_lane(dfi[abbrv], quantity)\n",
    "        temp_combo_df['%s %s' % (abbrv, quantity)] = quant_data\n",
    "        temp_combo_df['E-%s %s' % (abbrv, quantity)] = np.abs(temp_combo_df['Reference Value']-quant_data)\n",
    "\n",
    "    lane_chop = 6\n",
    "    temp_combo_df = temp_combo_df[temp_combo_df['Lane ID'] <= lane_chop]\n",
    "    \n",
    "    df_melted = pd.melt(temp_combo_df, id_vars=['Band ID'], value_vars=['E-GA Raw Volume', 'E-GA Background Corrected Volume', 'E-GG Raw Volume', 'E-GG Rolling Ball Corrected Volume'], var_name='Values')\n",
    "    \n",
    "    sns.boxplot(x='Band ID', y='value', hue='Values', data=df_melted, width=0.5)\n",
    "    # sns.boxplot(temp_combo_df, x='Band ID', y='GG Raw Volume')\n",
    "\n",
    "    # plt.scatter(reference_df[reference_df['Ladder'] == 'NEB']['Band ID']-1, reference_df[reference_df['Ladder'] == 'NEB']['Normalized_Intensity'],c='red')\n",
    "    print(temp_combo_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "543003b5-9e41-407d-9baa-aa9fb1ec4a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_count = 4\n",
    "sel_df = temp_combo_df[temp_combo_df['Band ID'] == 15]\n",
    "plt.scatter(range(lane_count), sel_df['E-GG Rolling Ball Corrected Volume'], label='GG Rolling Ball')\n",
    "plt.scatter(range(lane_count), sel_df['E-GA Background Corrected Volume'],c='red', label='GA')\n",
    "plt.scatter(range(lane_count), sel_df['E-GG Raw Volume'],c='green',label='raw GG')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e12be69-3952-4274-b19b-e8a5cd3bd3f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, df in ga_dfs.items():\n",
    "    id = int(key.split('_')[-1])\n",
    "    print(id,len(ga_dfs[key]), len(gg_dfs['gg_%s' % id]), len(origin_data[id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "47b62b9f-0aa9-479d-b92d-80c5945f3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
