{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Probability Map  Generation\n",
    "This file provides direct access to model outputs for downstream analysis."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a635ade41aa323c6"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from gelgenie.segmentation.evaluation.core_functions import segment_and_analyze, model_predict_and_process\n",
    "from gelgenie.segmentation.helper_functions.general_functions import create_dir_if_empty\n",
    "import toml\n",
    "import torch\n",
    "from gelgenie.segmentation.networks import model_configure\n",
    "from gelgenie.segmentation.helper_functions.stat_functions import load_statistics\n",
    "from torch.utils.data import DataLoader\n",
    "from gelgenie.segmentation.data_handling.dataloaders import ImageDataset, ImageMaskDataset\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def model_eval_load(exp_folder, eval_epoch):\n",
    "\n",
    "    model_config = toml.load(join(exp_folder, 'config.toml'))['model']\n",
    "    model, _, _ = model_configure(**model_config)\n",
    "    if eval_epoch == 'best':\n",
    "        stats = load_statistics(join(exp_folder, 'training_logs'), 'training_stats.csv', config='pd')\n",
    "        sel_epoch = stats['Epoch'][stats['Dice Score'].idxmax()]\n",
    "    else:\n",
    "        sel_epoch = eval_epoch\n",
    "\n",
    "    checkpoint = torch.load(f=join(exp_folder, 'checkpoints', 'checkpoint_epoch_%s.pth' % sel_epoch),\n",
    "                            map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(checkpoint['network'])\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T11:43:11.800483Z",
     "start_time": "2023-12-12T11:43:05.842707Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "experiment_names = ['unet_global_padding_nov_4']\n",
    "eval_epochs = [198]\n",
    "model_folder = '/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/segmentation_models/November 2023'\n",
    "output_folder = '/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/data/probability_map_samples'\n",
    "visual_out = join(output_folder, 'visual_segmentation_results')\n",
    "input_data = '/Users/matt/Documents/PhD/research_output/Automatic_Gel_Analyzer/data/probability_map_samples/true_data'\n",
    "images_folder = join(input_data, 'images')\n",
    "masks_folder = join(input_data, 'masks')\n",
    "proto_outputs = join(output_folder, 'prototyping')\n",
    "create_dir_if_empty(output_folder, visual_out, proto_outputs)\n",
    "\n",
    "models = []\n",
    "for experiment, eval_epoch in zip(experiment_names, eval_epochs):\n",
    "    exp_folder = join(model_folder, experiment)\n",
    "    model = model_eval_load(exp_folder, eval_epoch)\n",
    "    models.append(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:18:43.588926Z",
     "start_time": "2023-12-12T12:18:42.566126Z"
    }
   },
   "id": "d554b9e9e515ba76"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1;34mCreated dataset with \u001B[0m\u001B[1;34m9\u001B[0m\u001B[1;34m images.\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Created dataset with </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">9</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> images.</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:57<00:00,  6.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# testing direct model outputs\n",
    "segment_and_analyze(models, experiment_names, images_folder, visual_out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:15:32.770322Z",
     "start_time": "2023-12-12T12:14:35.179333Z"
    }
   },
   "id": "ee773fa1f8d650e2"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1;34mCreated dataset with \u001B[0m\u001B[1;34m1\u001B[0m\u001B[1;34m images.\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Created dataset with </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> images.</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [01:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43msegment_and_analyze\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexperiment_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/Users/matt/Desktop\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproto_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mminmax_norm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PhD/research_output/Automatic_Gel_Analyzer/main_code/python-gelgenie/gelgenie/segmentation/evaluation/core_functions.py:46\u001B[0m, in \u001B[0;36msegment_and_analyze\u001B[0;34m(models, model_names, input_folder, output_folder, minmax_norm)\u001B[0m\n\u001B[1;32m     43\u001B[0m     create_dir_if_empty(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(output_folder, mname))\n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m# preparing model outputs, including separation of different bands and labelling\u001B[39;00m\n\u001B[0;32m---> 46\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m im_index, batch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28menumerate\u001B[39m(dataloader), total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(dataloader)):\n\u001B[1;32m     48\u001B[0m     np_image \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39msqueeze()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m     49\u001B[0m     all_model_outputs \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/gel_segmentation/lib/python3.8/site-packages/tqdm/std.py:1195\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1192\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1195\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1196\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1197\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1198\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/gel_segmentation/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    649\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    650\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    651\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 652\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    653\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    654\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    655\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    656\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/gel_segmentation/lib/python3.8/site-packages/torch/utils/data/dataloader.py:692\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    690\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    691\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 692\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    693\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    694\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/gel_segmentation/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/gel_segmentation/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/Documents/PhD/research_output/Automatic_Gel_Analyzer/main_code/python-gelgenie/gelgenie/segmentation/data_handling/dataloaders.py:137\u001B[0m, in \u001B[0;36mImageDataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[1;32m    135\u001B[0m     img_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage_names[idx]\n\u001B[0;32m--> 137\u001B[0m     img_array \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_image\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimg_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maugmentations:\n\u001B[1;32m    140\u001B[0m         sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maugmentations(image\u001B[38;5;241m=\u001B[39mimg_array)  \u001B[38;5;66;03m# Apply augmentations\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/PhD/research_output/Automatic_Gel_Analyzer/main_code/python-gelgenie/gelgenie/segmentation/data_handling/dataloaders.py:100\u001B[0m, in \u001B[0;36mImageDataset.load_image\u001B[0;34m(self, filename)\u001B[0m\n\u001B[1;32m     97\u001B[0m image \u001B[38;5;241m=\u001B[39m ImageDataset\u001B[38;5;241m.\u001B[39mchannel_converter(image, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_channels)\n\u001B[1;32m     99\u001B[0m \u001B[38;5;66;03m# Normalizing image\u001B[39;00m\n\u001B[0;32m--> 100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241m.\u001B[39mminmax_norm:\n\u001B[1;32m    101\u001B[0m     min_pixel \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmin(image)\n\u001B[1;32m    102\u001B[0m     max_pixel \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmax(image)\n",
      "File \u001B[0;32m~/Documents/PhD/research_output/Automatic_Gel_Analyzer/main_code/python-gelgenie/gelgenie/segmentation/data_handling/dataloaders.py:100\u001B[0m, in \u001B[0;36mImageDataset.load_image\u001B[0;34m(self, filename)\u001B[0m\n\u001B[1;32m     97\u001B[0m image \u001B[38;5;241m=\u001B[39m ImageDataset\u001B[38;5;241m.\u001B[39mchannel_converter(image, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_channels)\n\u001B[1;32m     99\u001B[0m \u001B[38;5;66;03m# Normalizing image\u001B[39;00m\n\u001B[0;32m--> 100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241m.\u001B[39mminmax_norm:\n\u001B[1;32m    101\u001B[0m     min_pixel \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmin(image)\n\u001B[1;32m    102\u001B[0m     max_pixel \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmax(image)\n",
      "File \u001B[0;32m~/Applications/PyCharm Professional.app/Contents/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_trace_dispatch.py:92\u001B[0m, in \u001B[0;36mtrace_dispatch\u001B[0;34m(py_db, frame, event, arg)\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _trace_dispatch \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     91\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 92\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_trace_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpy_db\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx:1337\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx:1597\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.ThreadTracer.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx:1103\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx:1065\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Applications/PyCharm Professional.app/Contents/plugins/python/helpers/pydev/pydevd.py:1184\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1181\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1183\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1184\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Applications/PyCharm Professional.app/Contents/plugins/python/helpers/pydev/pydevd.py:1199\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1196\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1198\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1199\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1201\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1203\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "segment_and_analyze(models, experiment_names, '/Users/matt/Desktop', proto_outputs, minmax_norm=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:28:57.756958Z",
     "start_time": "2023-12-12T12:27:46.556060Z"
    }
   },
   "id": "7201133cb36d62bb"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1;34mClass weighting is \u001B[0m\u001B[1;34m[\u001B[0m\u001B[1;34m0.51268754\u001B[0m\u001B[1;34m]\u001B[0m\u001B[1;34m for background, \u001B[0m\u001B[1;34m[\u001B[0m\u001B[1;34m20.20436883\u001B[0m\u001B[1;34m]\u001B[0m\u001B[1;34m for bands\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Class weighting is [</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.51268754</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">] for background, [</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">20.20436883</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">] for bands</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1;34mCreated dataset with \u001B[0m\u001B[1;34m6\u001B[0m\u001B[1;34m images.\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Created dataset with </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">6</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> images.</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/_gjrrkj918v37xmw7d8n_p2h0000gn/T/ipykernel_3993/1272120084.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for im_index, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/6 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73d19f1636864f1db70ed3b0fe55b2f9"
      },
      "application/json": {
       "n": 0,
       "total": 6,
       "elapsed": 0.0219268798828125,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = ImageMaskDataset(images_folder, masks_folder, 1, padding=False, individual_padding=True)\n",
    "dataloader = DataLoader(dataset, shuffle=False, batch_size=1, num_workers=0, pin_memory=True)\n",
    "model_outputs = join(output_folder, 'direct_model_outputs')\n",
    "create_dir_if_empty(model_outputs)\n",
    "\n",
    "for im_index, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "    np_mask = batch['mask'].detach().squeeze().cpu().numpy()\n",
    "    name = batch['image_name'][0]\n",
    "    all_model_outputs = []\n",
    "    sel_image_folder = join(model_outputs, name)\n",
    "    create_dir_if_empty(sel_image_folder)\n",
    "    \n",
    "    seg_mask, seg_ordered_mask = model_predict_and_process(models[0], batch['image'])\n",
    "    np.save(join(sel_image_folder, 'seg_mask.npy'), seg_mask.detach().squeeze().cpu().numpy())\n",
    "    np.save(join(sel_image_folder, 'seg_mask_one_hot.npy'), seg_ordered_mask)\n",
    "    np.save(join(sel_image_folder, 'true_mask.npy'), np_mask)\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T15:41:11.210479Z",
     "start_time": "2023-11-26T15:40:55.938567Z"
    }
   },
   "id": "cc28194e620ab81"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1;34mClass weighting is \u001B[0m\u001B[1;34m[\u001B[0m\u001B[1;34m0.51281235\u001B[0m\u001B[1;34m]\u001B[0m\u001B[1;34m for background, \u001B[0m\u001B[1;34m[\u001B[0m\u001B[1;34m20.01243017\u001B[0m\u001B[1;34m]\u001B[0m\u001B[1;34m for bands\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Class weighting is [</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.51281235</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">] for background, [</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">20.01243017</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">] for bands</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1;34mCreated dataset with \u001B[0m\u001B[1;34m9\u001B[0m\u001B[1;34m images.\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Created dataset with </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">9</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> images.</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of images and masks do not match, there are 9 images and 8 masks.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mImageMaskDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmasks_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindividual_padding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m dataloader \u001B[38;5;241m=\u001B[39m DataLoader(dataset, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, pin_memory\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      3\u001B[0m model_outputs \u001B[38;5;241m=\u001B[39m join(output_folder, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdirect_model_outputs\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/PhD/research_output/Automatic_Gel_Analyzer/main_code/python-gelgenie/gelgenie/segmentation/data_handling/dataloaders.py:184\u001B[0m, in \u001B[0;36mImageMaskDataset.__init__\u001B[0;34m(self, images_dir, masks_dir, n_channels, mask_suffix, augmentations, padding, individual_padding, image_names, minmax_norm)\u001B[0m\n\u001B[1;32m    182\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNo images found in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmasks_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, make sure you put your masks there.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmask_names) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage_names):\n\u001B[0;32m--> 184\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNumber of images and masks do not match, there are \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage_names)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m images \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    185\u001B[0m                        \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mand \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmask_names)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m masks.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Number of images and masks do not match, there are 9 images and 8 masks."
     ]
    }
   ],
   "source": [
    "dataset = ImageMaskDataset(images_folder, masks_folder, 1, padding=False, individual_padding=True)\n",
    "dataloader = DataLoader(dataset, shuffle=False, batch_size=1, num_workers=0, pin_memory=True)\n",
    "model_outputs = join(output_folder, 'direct_model_outputs')\n",
    "\n",
    "create_dir_if_empty(model_outputs)\n",
    "\n",
    "# testing direct model outputs\n",
    "segment_and_analyze(models, experiment_names, images_folder, proto_outputs, minmax_norm=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:15:33.889122Z",
     "start_time": "2023-12-12T12:15:32.771487Z"
    }
   },
   "id": "a642e83664b4a5fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for im_index, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "    np_mask = batch['mask'].detach().squeeze().cpu().numpy()\n",
    "    name = batch['image_name'][0]\n",
    "    all_model_outputs = []\n",
    "    sel_image_folder = join(model_outputs, name)\n",
    "    create_dir_if_empty(sel_image_folder)\n",
    "    \n",
    "    seg_mask, seg_ordered_mask = model_predict_and_process(models[0], batch['image'])\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7cdbbdef0d5d5e7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
